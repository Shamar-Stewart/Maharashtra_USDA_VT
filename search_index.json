[["index.html", "Agricultural Outlook &amp; Forecasting Preface About the Authors", " Agricultural Outlook &amp; Forecasting Olga Isengildina Massa and Shamar L. Stewart August 2023 Preface This training program is designed to enhance the technical skills and background knowledge of agricultural outlook analysts. This program is largely based on materials developed by Drs. Olga Isengildina Massa and Shamar Stewart over 2019-2023 as part of a cooperative agreement between Virginia Tech and Economic Research Service (ERS) of the United States Department of Agriculture (USDA) targeted at enhancing the quality, communication and sustainability of the USDA commodity outlook program. Since 2021, the authors worked in collaboration with Foreign Agricultural Service (FAS) of the USDA to focus on more general materials that would be relevant for outlook analysts in the State of Maharashtra in India, as part of the State of Maharashtra Agribusiness and Rural Transformation (SMART) project. The objective of SMART is to support the development of inclusive and competitive agriculture value chains, focusing on small holder farmers and agri-entrepreneurs in Maharashtra. These training materials can be used to enhance technical capacity in agricultural outlook and forecasting. These materials cover both conceptual and applied topics focusing on modern tools relevant to agricultural outlook. We demonstrate various approaches to forecasting and discuss the advantages and pitfalls of these methods. About the Authors Olga Isengildina Shamar Stewart "],["public.html", "Module 1 Public Agricultural Outlook Programs: Structure, Role and Impact References", " Module 1 Public Agricultural Outlook Programs: Structure, Role and Impact Agricultural markets are characterized by pervasive uncertainty regarding future prices and quantities. The uncertainty can be attributed largely to a combination of a highly inelastic demand for food and a production technology that is subject to vagaries of nature such as weather, pests, and biological lags. This combination of factors results in a set of market prices that may vary substantially within a year and from year to year. The objective of public situation and outlook programs is to facilitate effective decision-making in this uncertain agricultural environment, where effective decision-making is defined as economic actions that result in higher profits, utility, and social welfare than otherwise would occur. The situation component of public programs is devoted to the production and collection of data, such as crop size, inventories of livestock, and producer acreage intentions. The outlook component is directed towards interpretation of the data and economic analysis. Economists believe that public agricultural forecasts help markets work more efficiently, ensuring reliable source of information. These forecasts help avoid the abuse of market power by large companies, leveling the playing field across market participants. Agricultural outlook programs also enable anticipatory policy development by the government. It is important to ensure that agricultural forecasts are provided by the government as market information is a public good and will be under-supplied by public sources. However, it is also important to find a balance on what forecasts are provided, how they are prepared and delivered given the technological revolution and shifting boundaries between public and private work. Public situation and outlook programs have a relatively long history. For example, the first national meeting generally is thought to be the U.S. Department of Agriculture’s Outlook Conference held on April 20, 1923. Since that time, situation and outlook programs have expanded considerably in scope, both at the federal level under the auspices of the U.S. Department of Agriculture (USDA) and at the state level within Land Grant Colleges of Agriculture. Expenditure on these programs in the US has been substantial. The Office of Management and Budget reported that out of “6.6 billion in total direct funding for major statistical programs across all Federal agencies in 2012, USDA accounted for about $521 million, or 7.8% of the total” (C-FARE, 2013, p. 4) Over 30% of these funds were allocated to the National Agricultural Statistical Service (NASS), an agency primarily responsible for data collection and dissemination. Because of their relevance and importance these forecasts sometimes become a center of controversy. One example begins in 1929 when the U.S. Congress singled out cotton in a notable policy restriction. Apparently, two years earlier, one of USDA’s routine monthly forecasts had projected lower cotton prices. When this forecast proved accurate, some in the cotton industry assumed that the forecast caused the price decline. This led to a political reaction where the USDA was banned from forecasting (only) cotton prices, a policy that remained in place until the 2008 Farm Bill. Another example includes corn futures prices posting their biggest drop in three years after the USDA estimated a bigger-than-expected crop on August 12, 2019, despite floods that slowed planting (Huffstutter and Polansek, 2019). This price drop caused an angry reaction from a farmer who threatened a USDA employee, which prompted USDA to pull its staff from a crop tour. While this report turned out to be accurate and USDA defended its methods, situations like this demonstrate the importance and the impact of USDA outlook reports. The materials in this module demonstrate how agricultural outlook programs differ around the world. The first is the presentation by Jennifer Bond and Ann Effland that discusses the history, structure and the changing role of the outlook program in the United States. The US public outlook program is one of the strongest and best funded in the world and serves as a benchmark for other outlook programs. Our second example describes the history, changing role and the current approaches used for the public sector forecasting in Australian agriculture. Just like in the US, the role of the public forecasting system has changed significantly over time due to changing priorities and resources. The current public forecasting system in Australia is much smaller than the US and therefore serves a different function. See ABARES Approach to Forecasting here. The similarities, differences and emerging issues in public outlook programs around the world were discussed further in a workshop conducted on October 14, 2020, which was hosted by Olga Isengildina Massa and moderated by Maurice Landes. The speakers included: Rohan Nelson, Program Leader, Agricultural Forecasting and Policy | Agriculture and Trade Branch | ABARES, Australia. Anastassios Haniotis, Director, DG Agriculture, European Union. Stephan Gagne, Deputy Director, Agriculture and Agri-Food Canada, Canada. Mark Jekanowski, Chairman, World Agricultural Outlook Board, USDA, USA. Comments were also provided by Utpal Vasavada, the Associate Direction of the Market and Trade Economics Division, USDA, USA. After viewing the workshop recording it is important to reflect and discuss how the issues mentioned in the workshops are similar or different from the situation in your country and the scale and resources available for public agricultural outlook in your case. How you can learn from the experiences in other countries to build the best possible outlook program that would be most suitable to your situation? Reflection Activity Have there been recent changes in the outlook program of your agency? What has been done? What new products or practices were implemented? Why? What issues were addressed? What are the emerging changes in outlook needs? What resources were required to implement these changes? What are the different platforms and timelines for publishing and dissemination? What staff and training needs had to be addressed to implement these changes? Are you using USDA outlook products? How? Has this changed? How do you assess commodity outlook information needs? How do you assess the impact of commodity outlook products? How do you collect feedback regarding the relevance of existing products? References Huffstutter, P., and Tom Polansek. 2019. “Farmer’s Threat Prompts U.S. Agriculture Department to Pull Staff from Crop Tour.” Available at: https://www.reuters.com/article/us-usa-grainstour- threat-idUSKCN1VB242 The Council on Food, Agricultural &amp; Resource Economics (C-FARE). (2013). Value of USDA Data Products. Washington, DC. "],["outlook.html", "Module 2 Agricultural Outlook Tools and Approaches 2.1 Balance Sheet Approach Exercise 2.2 Forecast selection and evaluation 2.3 References", " Module 2 Agricultural Outlook Tools and Approaches 2.1 Balance Sheet Approach One of the similarities between various outlook programs around the world is the use of the balance sheet approach for commodity outlook. The most prominent example of the balance sheet forecasts is the World Agricultural Supply and Demand Estimates (WASDE) reports from USDA. These reports cover numerous crops and livestock and are based on separate balance sheets that are maintained for over 90 countries. It is widely considered that these reports serve as benchmark balance sheet estimates for nearly all market participants. WASDE reports are released monthly 12 times a year and contain marketing year forecasts. Marketing year definitions vary by commodity, such as September – August for corn and soybeans, June – May for wheat, August – July for cotton, January – December for cattle and December – January for hogs. For all commodities, the first forecast is released in May before the marketing year and is finalized about 19 months later. Each month the forecast of the same event (marketing year value) is updated as more information becomes available. This means that the forecast errors become smaller across the forecasting cycle as more information becomes available. There are a number of agencies that participate in the WASDE process. For example, Foreign Agriculture Service (FAS): information regarding foreign production, use and trade Economic Research Service (ERS): identifies important economic effects and implications for prices, quantity supplied and quantity demanded. Farm Service Agency (FSA): describes current policy environment and farmers’ reaction to current policies. Agricultural Marketing Service (AMS): provides current price and marketing reports World Agricultural Outlook Board (WAOB): coordinates the interagency process used to produce WASDE estimates 2.1.1 Balance Sheet A balance sheet is one of the most popular tools used in fundamental analysis of commodity prices. It can be constructed for a particular crop, sector or the entire country. Typically, a construction of a balance sheet starts with building a supply side, followed by consumption, or use, side. The balance sheet ties both sides together by rationing available supplies to competing uses. Thus, a balance sheet is a joint system of interrelated forecasts. In a generic balance sheet, total supply is a sum of beginning stocks, production and imports. Total consumption (use) is a sum of domestic consumption, exports and residual. Endings stocks is a difference between total supply and total consumption. Exercise The following activity will help you practice your understanding of balance sheet equations described above. Using the information presented in the screenshot, complete the relevant line items of the WASDE balance sheet (Click the table to see the file with solution). While the balance sheet is a popular tool, it is often combined with and relies upon various other approaches to forecasting. These include time series approaches, futures-based models and other methods that will be discussed in detail later in this training course. But before we get to discussing specific methods, we need to discuss various criteria used for selecting what and how to forecast. 2.2 Forecast selection and evaluation Nelson et al. (2022a) argues that forecast quality is a much broader concept than accuracy. He mentions that forecast quality criteria should include availability, accuracy, timeliness, reliability and relevance, as shown in the figure below. Quality dimensions of agricultural forecasts Source: Cash et al. (2002), Nelson et al, (2022a). Based on these general criteria, ABARES evaluates the performance of their forecasts from three perspectives: the ability of the system to produce accurate forecasts, the ability of the system to meet changing institutional objectives (see Nelson, 2018), and the value–in–use of its forecasts to diverse end-users (see Nelson et al. (2022b) for details). This approach echoes the US two-prone system with a focus on what forecasts should be made and how to produce the most credible forecasts. The first question of what forecasts should be made stems from resource constraints. Since outlook information is a public good, the public will always request more information as it is distributed free of charge. However, resource limitations force public forecasters to focus on areas of biggest priorities. The challenge is that determining these biggest priorities may be difficult. This process boils down to determining forecasts of highest value and is revisited periodically during the times of budget pressures. The research report provided below is one of the most recent examples of such efforts. This report describes both the reasons for providing public agricultural outlook information and the foundation for assessing its value. The report provides a number of methods that can be used to assess the value of information and provides a framework for prioritizing data products. From Farm Income to Food Consumption: Valuing USDA Data Products After reviewing the report, it is important to reflect and discuss which methods and approaches mentioned in it would be appropriate for prioritizing data products in your situation. The answers to these questions will not be straight forward as political pressures are often present and may dictate what the priorities are regardless of economic reasons. The second component of forecast evaluation focuses on concepts of accuracy and efficiency. Academic literature describes a wide variety of methods that have been used to analyze the accuracy and efficiency of USDA forecasts. Most studies assume that forecasters minimize a symmetric linear or quadratic loss function, mean absolute errors (MAE) and root mean squared errors (RMSE) are the standard measures of accuracy reflecting the magnitude of forecast errors. Only one study by Bora, Katchova and Kuethe (2020) explored the possibility of asymmetric loss functions for USDA forecast providers with different weights placed on over or under-prediction. While most studies evaluate forecasts as published values, some (e.g., Isengildina, MacDonald and Xie, 2012) express forecasts as percent changes from previous year’s values. The evaluation of accuracy typically focuses on forecast errors measured as the difference between the realized value and the predicted value and expressed in either raw units or percentages or log percentages to control for changes in levels of the forecasted variable over time. These measures are typically used to compare the accuracy of forecasts in question to a certain benchmark, such as naïve forecast (using Theil’s U statistic), or a time-series forecast, or another alternative forecast. Modified Diebold Mariano test (Harvey, Leybourne, and Newbold, 1997) is typically used to determine whether the difference between the accuracy of two alternative forecasts is significantly different from zero. The results of this evaluation would indicate which forecast is more accurate relative to the included alternative. Most of the previous studies conduct accuracy evaluation at each forecast horizon, as fixed-event forecasts are expected to become more accurate across the forecasting cycle as more information becomes available. Some recent studies proposed methods to compare the relative accuracy of path forecasts (e.g., Patton and Timmerman, 2012). For example, Bora, Katchova, and Kuethe (2022) use the tests of multi-horizon superior predictive ability proposed by Quaedvlieg (2021) that jointly consider all horizons along the entire projection path. These tests evaluate the average superior predictive ability for a path forecast with larger loss at some horizons that is compensated by superior performance at other horizons when compared to the alternative path forecast. Some studies (e.g., Isengildina, MacDonald and Xie, 2012) also used a directional accuracy test developed by Henriksson and Merton (1981). The test is based on 2 x 2 contingency tables, reflecting the direction of year-to-year change in each variable forecast for each stage’s average forecast. The frequency with which forecasts and actual realizations of the variable decrease or increase together is compared with the expected frequency of independent directional changes using a Chi-squared statistic. The results of this evaluation reflect a proportion of time the forecast correctly predicts the directional change in the realized value. Theil (1958) developed the original the framework for rolling-event forecast efficiency testing, which was extended by Mincer and Zarnowitz (1969). Nordhaus (1987) introduced the utilization of these tests into a fixed-event framework, and Clements (1997) extended this to the pooling of rolling sets of fixed-event forecasts. The fundamental measures of optimal forecasts are bias and efficiency (Diebold and Lopez, 1998). Tests of bias examine whether positive and negative forecast errors cancel out and the average forecast errors equal zero. Traditionally, this condition has been tested with a simple t-test, but some studies have applied a regression-based test of bias developed by Holden and Peel (1990), in which the error is regressed against a constant. The benefit of this approach is that it allows for heteroscedasticity and autocorrelation correction of standard errors following Newey and West (1987). Variations of this test include a trend variable to assess whether bias has changed over time. Other studies (e.g., Sanders and Manfredo, 2007) have applied what is widely known as a Mincer-Zarnowitz equation to assessing forecast bias. In this approach a realized value is regressed against the constant, the forecast and the error term. This regression tests whether forecasts are unbiased (coefficient for constant is zero) and properly scaled (coefficient for forecast is one). However, estimation of this equation may encounter statistical challenges, especially when there is lack of stationarity in either realized values or forecasts. Tests of weak-form efficiency typically examine whether forecast errors are orthogonal to forecasts themselves and prior forecast errors (e.g., Sanders and Manfredo, 2002, 2003; Isengildina, MacDonald and Xie, 2012). Some studies also assessed orthogonality to other information available at the time the forecasts are made (e.g. Isengildina-Massa, Karali, and Irwin, 2013). Studies also assessed changes in forecast accuracy over time (e.g., Bailey and Brorsen, 1998; Sanders and Manfredo, 2003; Isengildina, MacDonald and Xie, 2012) by regressing absolute forecast errors against a constant and a time trend. Fixed-event forecast errors should also demonstrate a pattern of errors decreasing across the forecast horizon as more information becomes available (e.g., Isengildina-Massa, Karali, and Irwin, 2013; Isengildina, MacDonald and Xie, 2012). Weak form efficiency of fixed-event forecasts also implies independence of forecast revisions (Nordhaus, 1987). According to Nordhaus, if forecasts are weak form efficient, revisions should follow a random walk. This condition has been tested extensively in previous studies by Isengildina, Irwin and Good (2006), Sanders, Altman, and Manfredo (2009), Isengildina, Irwin and Good (2013), Isengildina, MacDonald and Xie (2012), MacDonald and Ash (2016), and MacDonald, Ash and Cooke (2017), among others. However, the interpretation of this test results has changed over time. While some earlier studies (Isengildina, Irwin and Good, 2006; Sanders, Altman, Manfredo, and Anderson, 2009; Isengildina, Irwin and Good, 2013; Isengildina, MacDonald and Xie, 2012) interpreted evidence of correlation in forecast revisions as “smoothing,” suggesting of strategic behavior of forecast providers, Goyal and Adjemian (2023) argued that correlated revisions may also be explained by information rigidities that cause forecasts to be infrequently or only partially updated. The authors apply a framework developed by Coibion and Gorodnichenko (2015) to demonstrate that information rigidities are the most likely cause of correlations in crop production revisions due to production and yield data that is either too costly to obtain or too noisy. Numerous studies demonstrated that combination forecasts provide accuracy benefits (e.g., Colino and Irwin, 2010; Colino, Irwin, and Garcia, 2012, Hoffman et al, 2015). A related test developed by Harvey, Leybourne and Newbold (1998) assesses forecast encompassing. If a preferred forecast encompasses an alternative forecast, then the alternative forecast provides no useful information beyond that provided in the preferred forecast. This test is based on a regression used to evaluate the covariance between the preferred forecast error series (dependent variable) and the difference between the preferred and alternative forecast error series (independent variable). If this covariance is zero, the preferred forecast is said to encompass the competing one. This test has been used extensively to demonstrate whether additional information, such as time series forecasts (e.g. Sanders and Manfredo, 2003), or futures-based forecasts (e.g, Hoffman et al, 2015; Colino and Irwin, 2010) may help improve USDA forecasts. As most USDA forecasts are released at multiple horizons (several months, quarters or years, another important criterion for their evaluation is informational content. Earlier studies (e.g., Sanders and Manfredo, 2008) used the direct test developed by Vuchelen and Gutierrez (2005). for evaluation of information content across multiple horizons. This test establishes the contribution of longer-horizon forecasts relative to the information contained in shorter-horizon forecasts. More recent studies (e.g., Luke and Tonsor, 2023; Bora, Katchova, and Kuethe, 2022) used the test developed by Breitung and Knuppel (2021) to determine the maximum informative projection horizon by comparing the projections’ mean-squared prediction errors to the variance of the evaluation sample. The benefit of this test is that it circumvents the need to compare projections to naïve benchmarks and instead compares prediction errors to the variance of realized values. As some USDA forecasts are released as part of joint system (e.g. WASDE forecasts, farm income forecasts), it is important to consider the joint accuracy of the system and interaction of various components within a system. Only a few studies addressed these issues. For example, Isengildina-Massa et al, 2021, used a test developed by Sinclair, Stekler, and Carnow (2015) which combines the single accuracy measure for each component of the joint forecasts into a vector. Specifically, it focuses on the difference (Mahalanobis distance) between the mean vectors of forecasts and outcomes while allowing for scale differences across different variables and a nonzero correlation between variables. The rationale behind this test is that if a vector of forecasts is similar to the vector of the outcomes, it can be substituted for the actual data for decision making. The interaction of various components is usually determined through evaluation of the residual variable (ending stocks for WASDE, or Net Cash Income or Net Farm Income for farm income) and determination of the contribution of errors in various components of the balance sheet (or income statement) to the errors in the residual variable. Most studies have approached it using regression or correlation analysis (e.g., Botto et al, 2006; Isengildina-Massa, Karali, Irwin, 2013; Isengildina-Massa et al, 2019). Recently, Goyal et al, 2023 proposed the use of machine learning methods to decompose USDA ending stocks errors to avoid the issues of multicollinearity inherent in regression analysis used for this purpose. The authors use extreme gradient boosting trees to determine the relative importance of each component of the balance sheet. Additionally, Goyal et al, 2023, use Shapley additive explanations (SHAP) values (Lundberg and Lee, 2017) to quantify the extent to which ending stocks prediction error increases or decreases from the average prediction error due to the inclusion of a given predictor variable. Finally, it is important to note that all of the above methods have been developed and applied to point forecasts, which is how most of the USDA projections are published. Only price forecasts have been published as ranges until 2019. Most of the early studies reduced these ranges to their midpoint for evaluation, with some exceptions. Sanders and Manfredo (2003) were the first to calculate “hit rates,” the proportion of time the forecast interval contained the final value. Isengildina, Irwin and Good, (2004) applied Christoffersen’s (1998) unconditional coverage test to determine whether forecast hit rates was significantly different from the implied confidence level. Isengildina-Massa and Sharp (2012) extended this analysis to account for asymmetry in forecast errors. A number of studies (e.g, Adjemian, Bruno, and Robe, 2020; Trujillo-Barrera, Garcia, Mallory, 2016; Isengildina-Massa, Irwin, and Good, 2010, 2011) proposed various methods of improving USDA price forecast intervals. One of the most important aspects of forecast evaluation is data availability. Forecasting agencies around the world (e.g., Farm Income and Wealth Statistics Forecast and Estimate Data Archive, and Cameron and Nelson, 2022) have made extensive efforts to enable users to evaluate the accuracy of their forecasts by providing historical databases of their projections and realized values. This process helps ensure transparency and communication between forecast providers and data users. Historical databases are also necessary for computing forecasts, as most of them are based on patterns in the data over time. The following modules will describe the use of R codes for data manipulation and computation of various forecasts relevant for modern agricultural outlook. We will illustrate coding and forecasting concepts using US forecasts due to data availability, but these concepts can be applied to Maharashtra’s data in a similar manner. Modules 3 – 6 describe various forecasting approaches and Module 7 will focus on forecast accuracy evaluations. 2.3 References Adjemian, M.K., V.G. Bruno, and M.A. Robe. 2020. “Incorporating Uncertainty into USDA Commodity Price Forecasts.” American Journal of Agricultural Economics 102(2):696-712. Bailey, D. and Brorsen, B. 1998. “Trends in the Accuracy of USDA Production forecasts for Beef and Pork”. Journal of Agricultural and Resource Economics, 23:515–526. Bora, S.S., A.L. Katchova, and T.H. Kuethe. 2020. “The Rationality of USDA Forecasts under Multivariate Asymmetric Loss.” American Journal of Agricultural Economics 103(3): 1006-1033. Bora, Siddhartha S., Ani L. Katchova, and Todd H. Kuethe. 2022. “The Accuracy and Informativeness of Agricultural Baselines.” American Journal of Agricultural Economics, DOI: 10.1111/ajae.12350 Botto, A.C., O. Isengildina, S.H. Irwin, and D.L. Good. 2006. “Accuracy Trends and Sources of Forecast Errors in WASDE Balance Sheet Categories for Corn and Soybeans.” American and Applied Economics Association Annual Meeting, Long Beach, CA, July 23-26, 2006. Breitung, EvJrg, and Malte Knüppel. 2021. “How Far Can We Forecast? Statistical Tests of the Predictive Content.” Journal of Applied Econometrics 36: 369–92. Cameron, A., and R. Nelson. 2022. “Enabling Users to Evaluate the Accuracy of ABARES Agricultural Forecasts.” Australian Agribusiness Review, 30,7, ISSN: 1883-5675. Cash, D., Clark, W.C., Alcock, F., Dickson, N.M., Eckley, N. and Jäger, J. (2002), Salience, Credibility, Legitimacy and Boundaries: Linking Research, Assessment and Decision Making, John F Kennedy School of Government Faculty Research Working Papers Series RWP02-046. Harvard University, Cambridge. Christoffersen,P.F. “Evaluating Interval Forecasts.” International Economic Review 39(1998):841–62. Clements, M. P. 1997. “Evaluating the Rationality of Fixed-Event Forecasts.” Journal of Forecasting 16: 225–239. Coibion, O., and Y. Gorodnichenko. 2015. “Information rigidity and the expectations formation process: a simple framework and new facts.” American Economic Review. https://doi.org/10.1257/aer.20110306 Colino, E.V., and S.H. Irwin. 2010. “Outlook vs. Futures: Three Decades of Evidence in Hog and Cattle Markets.” American Journal of Agricultural Economics, 92(1): 1-15. Colino, E.V., S.H. Irwin, and P. Garcia. 2012. “Improving the Accuracy of Outlook Price Forecasts.” Agricultural Economics 42: 357-371. Diebold, F. X. and J. A. Lopez. “Forecasting Evaluation and Combination.” In G. S. Maddala and C. R. Rao, eds., Handbook of Statistics 14: Statistical Methods in Finance, Amsterdam: North-Holland, 1998, 241–268. Goyal, R. M.K.Adjenian, J. Glauber, and S. Meyer. 2023. “Decomposing USDA Ending Stocks Forecast Errors.” Journal of Agricultural and Resource Economics, ISSN: 1068-5502 (Print); 2327-8285 (Online) doi: 10.22004/ag.econ.320674 Goyal, R., and M.K. Adjemian. 2023. “Information Rigidities in USDA Crop Production Forecasts.” American Journal of Agricultural Economics, in press, doi.org/10.1111/ajae.12373. Harvey, D. I., Leybourne, S. J., &amp; Newbold, P. (1998). Tests for forecast encompassing. Journal of Business &amp; Economic Statistics, 16(2), 254–259. doi: 10.1080/07350015.1998.10524759 Harvey, D., Leybourne, S., &amp; Newbold, P. (1997). Testing the equality of prediction mean squared errors. International Journal of forecasting, 13(2), 281–291. doi: 10.1016/S01692070(96)007194 Henriksson, R. D. and R. C. Merton. “On Market Timing and Investment Performance. II. Statistical Procedures for Evaluating Forecasting Skills.” Journal of Business 54(1981):513–533. Hoffman, L.A., X.L. Etienne, S.H. Irwin, E.V. Colino, and J.I. Toasa. 2015. “Forecast Performance of WASDE Price Projections for U.S. Corn.” Agricultural Economics 46(S1):157-171. Holden, K. and Peel, D. A. (1990). “On Testing for Unbiasedness and Efficiency of Forecasts.” Manchester School, 58:120–127. Isengildina, O., S.H. Irwin, and D.L. Good. 2004. “Evaluation of USDA Interval Forecasts of Corn and Soybean Prices.” American Journal of Agricultural Economics 86(4):990-1004. Isengildina, O., S.H. Irwin, and D.L. Good. 2006. “Are Revisions to USDA Crop Production Forecasts Smoothed?” American Journal of Agricultural Economics 88(4):1091-1104. Isengildina, O., S.H. Irwin, and D.L. Good. 2013. “Do Big Crops Get Bigger and Small Crops Get Smaller? Further Evidence on Smoothing in USDA Forecasts.” Journal of Agricultural and Applied Economics 45(1):95-107. Isengildina‐Massa, O., and J.L. Sharp. 2012. “Evaluation of USDA Interval Forecasts Revisited: Asymmetry and Accuracy of Corn, Soybean, and Wheat Prices.” Agribusiness 28(3):310-323. Isengildina-Massa, O., B. Karali, and S.H. Irwin. 2013. “When Do the USDA Forecasters Make Mistakes?” Applied Economics 45(36):5086-5103. Isengildina-Massa, O., Karali, B., Kuethe, T. H., and Katchova, A. L. (2021). “Joint Evaluation of the System of USDA’s Farm Income Forecasts.” Applied Economic Perspectives and Policy, 43(3):1140–1160. Isengildina-Massa, O., Karali, B., Kuethe, T. H., and Katchova, A. L. 2019. “Sources of Errors in USDA’s Net Cash Income Forecasts”. NCCC-134 paper. (https://ageconsearch.umn.edu/record/309630/?ln=en). Isengildina-Massa, O., S. MacDonald, and R. Xie. 2012. “A comprehensive Evaluation of USDA Cotton Forecasts.” Journal of Agricultural and Resource Economics 37(1):98-113. Isengildina-Massa, O., S.H. Irwin, and D.L. Good. 2010. “Quantile Regression Estimates of Confidence Intervals for WASDE Price Forecasts.” Journal of Agricultural and Resource Economics 35(3):545-567. Isengildina-Massa, O., S.H. Irwin, D.L. Good, and L. Massa. 2011. “Empirical Confidence Intervals for USDA Commodity Price Forecasts.” Applied Economics 43(26):3789-3803. Luke, J.R., and G.T. Tonsor. 2023. “USDA Long-Term Meat Trade Projections: A Comprehensive Evaluation.” Journal of Agricultural and Applied Economics, DOI:10.1017/aae.2023.13. Lundberg, S.M., and S.-I. Lee. 2017. “A unified approach to interpreting model predictions.” Advances in Neural Information Processing Systems 4765-4774. Accessed at:https://doi.org/10.48550/arXiv.1705.07874 MacDonald, S. and M. Ash. 2016. “Detecting the Sources of Information Rigidity: Analyzing Forecast Bias and Smoothing in USDA’s Soybean Forecasts.” AAEA paper. (https://ageconsearch.umn.edu/record/235349) MacDonald, S., M. Ash and B. Cooke. 2017. “The Evolution of Inefficiency in USDA’s Forecasts of U.S. and World Soybean Markets.” MPRA Paper No. 87545 (https://mpra.ub.uni-muenchen.de/87545/) Mincer, J. A. and V. Zarnowitz. “The Evaluation of Economic Forecasts.” In J. A. Mincer,ed., Economic Forecasts and Expectations: Analysis of Forecasting Behavior and Performance,Washington, DC: National Bureau of Economic Research, 1969, 1–46. Nelson, R. (2018), ‘The future of public sector forecasting in Australian agriculture’, Australasian Agribusiness Perspectives 21, paper 16. Nelson, R., A. Cameron, C. Xia, and P. Gooday. 2022a. “The ABARES Approach to Forecasting Agricultural Commodity Markets – Description and Design Choices.” Australian Agribusiness Review 30, 6, ISSN: 1883-5675. Nelson, R., Cameron, A., Xia, C., Howden, M. and Miller, M. 2022b. The Australian Agricultural Forecasting System - System Documentation, Technical Report 22.02. Australian Bureau of Agricultural and Resource Economics and Sciences, Canberra. Newey, W. K., and K. D. West. 1987. “A Simple, Positive Semi-Definite, Heteroskedasticity and Autocorrelation.” Econometrica 55: 703–8. Nordhaus, W. D. “Forecasting Efficiency: Concepts and Applications.” The Review of Economics and Statistics 69(1987):667–674. Patton, A. and Timmermann, A. (2007). “Properties of Optimal Forecasts under Asymmetric Loss and Nonlinearity. Journal of Econometrics, 140:884–918. Quaedvlieg, Rogier. 2021. “Multi-Horizon Forecast Comparison.” Journal of Business &amp; Economic Statistics 39: 40–53. Sanders, D. and Manfredo, M. (2003). “USDA Livestock Price Forecasts: A Comprehensive Evaluation.” Journal of Agricultural and Resource Economics, 28:316–336. Sanders, D. and Manfredo, M. (2007). “Rationality of U.S. Department of Agriculture Livestock Price Forecasts: A Unified Approach.” Journal of Agricultural and Applied Economics 39(1): 75-85. Sanders, D. and Manfredo, M. (2008). “Multiple Horizons and Information in USDA production forecasts.” Agribusiness, 24(1):55-66. Sanders, D. R. and M. R. Manfredo. (2002). “USDA Production Forecasts for Pork, Beef, and Broilers: An Evaluation.” Journal of Agricultural and Resource Economics 27:114–128. Sanders, D.R., I.J. Altman, M.R. Manfredo, and R. Anderson. 2009. “Using USDA Production Forecasts: Adjusting for Smoothing.” Journal of ASFMRA, 134-142. Sinclair, T.M., H.O. Stekler, and W. Carnow. 2015. Evaluating a Vector of the Fed’s Forecasts. International Journal of Forecasting 31: 157–164. Theil, H. 1958. Economic Forecasts and Policy. Amsterdam: North-Holland Publishing Co. Trujillo-Barrera, A, Garcia, P., and Mallory, M.L. 2016. “Price Density Forecasts in the U.S. Hog Markets: Composite Procedures.” American Journal of Agricultural Economics 98(5): 1529-1544. Vuchelen, J., &amp; Gutierrez, M.-I. (2005). A direct test of the information content of the OECD growth forecasts. International Journal of Forecasting, 21, 103–117. "],["data.html", "Module 3 Data Manipulation, Visualization, and Basic Forecasting Optional Materials 3.1 NASS QuickStats 3.2 Data Manipulation 3.3 Visualizing Time Series Data 3.4 Benchmark Forecasting Methods Exercise", " Module 3 Data Manipulation, Visualization, and Basic Forecasting In this module, we will focus on importing, manipulating, and visualizing time series data in R. Towards the end, we will estimate and graph the forecasts of a few basic time series models. For much of our exercises, we will focus on importing data from the USDA’s NASS QuickStats database. Optional Materials While these modules are intended to be self-contained, they also build on the MTED-R-Training Workshop from the USDA. It would be a worthwhile exercise to review the R basics, Data Importation, and Data Transformation modules. This would prove especially useful for the new(er) users of R. 3.1 NASS QuickStats The US Department of Agriculture (USDA)’s National Agricultural Statistical Agency (NASS) has an R package called tidyUSDA that connect directly to an API and allows users to download QuickStats data into R (See MTED-R-Training). Additionally, tidyUSDA gives you the option to explore the QuickStats data at either the county or national level. This allows you to quickly visualize data for report generation. In this example, we will use an API to pull the Corn GRAIN - PRICE RECEIVED, MEASURED in $ / BU data series into R. Our ultimate goal is to explore the data and perform some basic forecasting. We will reserve the evaluation of these models for later modules. 3.1.1 tidyUSDA package If you have never done so before, you will need to install the tidyUSDA package. You can achieve this using the syntax below. We suggest running this code in your console and not scripts. You need only install this package once. install.packages(&quot;tidyUSDA&quot;) In subsequent sessions you can simply call the library into memory. library(tidyUSDA) 3.1.2 API Key In order to pull data directly into R, you will need an API key. Please click here to obtain a free API Key via email. Return to this page once you have been issued a key. Now that you have obtained your API Key, you can supply it to R for use in this and subsequent sessions. There are two approaches you could take: Approach 1: You could hard code your key (Not Recommended). key &lt;- &quot;PUT-YOUR-KEY-HERE&quot; If you R scripts will be public facing, this might not be a desirable option. Approach 2: Using the keyring package To help with protecting your API Key we will use the keyring package. You might need to install the keyring package first. You can repeat the same step from earlier to get this done. # Load the Keyring package library(keyring) # Save the API Key (you can skip this step in the future) #tidyUSDA is the nickname assigned for my API key combination key_set(&quot;tidyUSDA&quot;) A password prompt should now appear. Enter your API key and click OK. Keyring Password Prompt For this and future sessions, you can use the key_get command to retrieve the key. To do so, run the following line key &lt;- keyring::key_get(&quot;tidyusda&quot;) We can determine the relevant parameters for our search by visiting the Quickstats website. We are ready to pull the Corn GRAIN - PRICE RECEIVED, MEASURED in $ / BU data. 3.1.3 Writing a Query corn &lt;- tidyUSDA::getQuickstat( key = key, program = &quot;SURVEY&quot;, sector = &quot;CROPS&quot;, group = &quot;FIELD CROPS&quot;, commodity = &quot;CORN&quot;, category = &quot;PRICE RECEIVED&quot;, data_item = &quot;CORN, GRAIN - PRICE RECEIVED, MEASURED in $ / BU&quot;, domain = &quot;TOTAL&quot;, geographic_level = &quot;NATIONAL&quot;, state = &quot;US TOTAL&quot;, #Must specify years as character variables year = as.character(c(1990:2019)) ) We have a number of approaches to be able to see the full data. First, we can call the variable name in R.1 corn You can use the View() command to explore the dataset in your R environment. View(corn) Alternatively, we can view the head (first n observations). R will default to n = 6. head(corn, 10) ## week_ending class_desc year ## 1 ALL CLASSES 2019 ## 2 ALL CLASSES 2019 ## 3 ALL CLASSES 2019 ## 4 ALL CLASSES 2019 ## 5 ALL CLASSES 2019 ## 6 ALL CLASSES 2019 ## 7 ALL CLASSES 2019 ## 8 ALL CLASSES 2019 ## 9 ALL CLASSES 2019 ## 10 ALL CLASSES 2019 ## short_desc state_name county_ansi ## 1 CORN, GRAIN - PRICE RECEIVED, MEASURED IN $ / BU US TOTAL ## 2 CORN, GRAIN - PRICE RECEIVED, MEASURED IN $ / BU US TOTAL ## 3 CORN, GRAIN - PRICE RECEIVED, MEASURED IN $ / BU US TOTAL ## 4 CORN, GRAIN - PRICE RECEIVED, MEASURED IN $ / BU US TOTAL ## 5 CORN, GRAIN - PRICE RECEIVED, MEASURED IN $ / BU US TOTAL ## 6 CORN, GRAIN - PRICE RECEIVED, MEASURED IN $ / BU US TOTAL ## 7 CORN, GRAIN - PRICE RECEIVED, MEASURED IN $ / BU US TOTAL ## 8 CORN, GRAIN - PRICE RECEIVED, MEASURED IN $ / BU US TOTAL ## 9 CORN, GRAIN - PRICE RECEIVED, MEASURED IN $ / BU US TOTAL ## 10 CORN, GRAIN - PRICE RECEIVED, MEASURED IN $ / BU US TOTAL ## country_code freq_desc state_alpha statisticcat_desc watershed_desc ## 1 9000 ANNUAL US PRICE RECEIVED ## 2 9000 ANNUAL US PRICE RECEIVED ## 3 9000 MONTHLY US PRICE RECEIVED ## 4 9000 MONTHLY US PRICE RECEIVED ## 5 9000 MONTHLY US PRICE RECEIVED ## 6 9000 MONTHLY US PRICE RECEIVED ## 7 9000 MONTHLY US PRICE RECEIVED ## 8 9000 MONTHLY US PRICE RECEIVED ## 9 9000 MONTHLY US PRICE RECEIVED ## 10 9000 MONTHLY US PRICE RECEIVED ## unit_desc CV (%) domaincat_desc region_desc asd_code domain_desc end_code ## 1 $ / BU NOT SPECIFIED TOTAL 00 ## 2 $ / BU NOT SPECIFIED TOTAL 00 ## 3 $ / BU NOT SPECIFIED TOTAL 01 ## 4 $ / BU NOT SPECIFIED TOTAL 02 ## 5 $ / BU NOT SPECIFIED TOTAL 03 ## 6 $ / BU NOT SPECIFIED TOTAL 04 ## 7 $ / BU NOT SPECIFIED TOTAL 05 ## 8 $ / BU NOT SPECIFIED TOTAL 06 ## 9 $ / BU NOT SPECIFIED TOTAL 07 ## 10 $ / BU NOT SPECIFIED TOTAL 08 ## Value state_ansi agg_level_desc group_desc asd_desc load_time ## 1 3.56 NATIONAL FIELD CROPS 2021-11-30 15:01:54.000 ## 2 3.75 NATIONAL FIELD CROPS 2022-07-29 15:01:54.000 ## 3 3.56 NATIONAL FIELD CROPS 2021-09-30 15:01:42.000 ## 4 3.60 NATIONAL FIELD CROPS 2021-09-30 15:01:42.000 ## 5 3.61 NATIONAL FIELD CROPS 2021-09-30 15:01:42.000 ## 6 3.53 NATIONAL FIELD CROPS 2021-09-30 15:01:42.000 ## 7 3.63 NATIONAL FIELD CROPS 2021-09-30 15:01:42.000 ## 8 3.98 NATIONAL FIELD CROPS 2021-09-30 15:01:42.000 ## 9 4.16 NATIONAL FIELD CROPS 2021-11-30 15:01:54.000 ## 10 3.93 NATIONAL FIELD CROPS 2021-11-30 15:01:54.000 ## watershed_code state_fips_code reference_period_desc county_name ## 1 00000000 99 MARKETING YEAR ## 2 00000000 99 YEAR ## 3 00000000 99 JAN ## 4 00000000 99 FEB ## 5 00000000 99 MAR ## 6 00000000 99 APR ## 7 00000000 99 MAY ## 8 00000000 99 JUN ## 9 00000000 99 JUL ## 10 00000000 99 AUG ## congr_district_code county_code util_practice_desc source_desc ## 1 GRAIN SURVEY ## 2 GRAIN SURVEY ## 3 GRAIN SURVEY ## 4 GRAIN SURVEY ## 5 GRAIN SURVEY ## 6 GRAIN SURVEY ## 7 GRAIN SURVEY ## 8 GRAIN SURVEY ## 9 GRAIN SURVEY ## 10 GRAIN SURVEY ## commodity_desc country_name prodn_practice_desc location_desc ## 1 CORN UNITED STATES ALL PRODUCTION PRACTICES US TOTAL ## 2 CORN UNITED STATES ALL PRODUCTION PRACTICES US TOTAL ## 3 CORN UNITED STATES ALL PRODUCTION PRACTICES US TOTAL ## 4 CORN UNITED STATES ALL PRODUCTION PRACTICES US TOTAL ## 5 CORN UNITED STATES ALL PRODUCTION PRACTICES US TOTAL ## 6 CORN UNITED STATES ALL PRODUCTION PRACTICES US TOTAL ## 7 CORN UNITED STATES ALL PRODUCTION PRACTICES US TOTAL ## 8 CORN UNITED STATES ALL PRODUCTION PRACTICES US TOTAL ## 9 CORN UNITED STATES ALL PRODUCTION PRACTICES US TOTAL ## 10 CORN UNITED STATES ALL PRODUCTION PRACTICES US TOTAL ## begin_code zip_5 sector_desc ## 1 00 CROPS ## 2 00 CROPS ## 3 01 CROPS ## 4 02 CROPS ## 5 03 CROPS ## 6 04 CROPS ## 7 05 CROPS ## 8 06 CROPS ## 9 07 CROPS ## 10 08 CROPS 3.2 Data Manipulation 3.2.1 Subseting &amp; Filtering Much of our data manipulations can be performed quickly (and efficiently) using the tidyverse environment. The tidyverse package is very powerful and speeds up the data cleaning and manipulation process. Unfortunately, much of the functionalities we require are missing from the package of the same name. For our purpose and given our focus on time series, we will use the fpp3 package that accompanies the free text Forecasting: Principles and Practice (3rd ed) by Rob J Hyndman and George Athanasopoulos. This package builds on the tidyverse/dplyr packages and a number of packages dedicated to time series models. This would be a good time to install the fpp3 package. install.packages(&quot;fpp3&quot;) Since there are so many columns in this dataset, we can drop all irrelevant columns. For our purposes assume further that we need to get the price data at the annual (YEAR) frequency. It might prove easier if we were to first filter the data on the reference_period_desc column. We will keep only the rows that meet the criterion of reference_period_desc == \"YEAR\" library(fpp3) ## ── Attaching packages ────────────────────────────────────────────── fpp3 0.5 ── ## ✔ tibble 3.2.1 ✔ tsibble 1.1.3 ## ✔ dplyr 1.1.2 ✔ tsibbledata 0.4.1 ## ✔ tidyr 1.3.0 ✔ feasts 0.3.1 ## ✔ lubridate 1.9.2 ✔ fable 0.3.3 ## ✔ ggplot2 3.4.2 ✔ fabletools 0.3.3 ## ── Conflicts ───────────────────────────────────────────────── fpp3_conflicts ── ## ✖ lubridate::date() masks base::date() ## ✖ dplyr::filter() masks stats::filter() ## ✖ tsibble::intersect() masks base::intersect() ## ✖ tsibble::interval() masks lubridate::interval() ## ✖ dplyr::lag() masks stats::lag() ## ✖ tsibble::setdiff() masks base::setdiff() ## ✖ tsibble::union() masks base::union() # View the column names colnames(corn) ## [1] &quot;week_ending&quot; &quot;class_desc&quot; &quot;year&quot; ## [4] &quot;short_desc&quot; &quot;state_name&quot; &quot;county_ansi&quot; ## [7] &quot;country_code&quot; &quot;freq_desc&quot; &quot;state_alpha&quot; ## [10] &quot;statisticcat_desc&quot; &quot;watershed_desc&quot; &quot;unit_desc&quot; ## [13] &quot;CV (%)&quot; &quot;domaincat_desc&quot; &quot;region_desc&quot; ## [16] &quot;asd_code&quot; &quot;domain_desc&quot; &quot;end_code&quot; ## [19] &quot;Value&quot; &quot;state_ansi&quot; &quot;agg_level_desc&quot; ## [22] &quot;group_desc&quot; &quot;asd_desc&quot; &quot;load_time&quot; ## [25] &quot;watershed_code&quot; &quot;state_fips_code&quot; &quot;reference_period_desc&quot; ## [28] &quot;county_name&quot; &quot;congr_district_code&quot; &quot;county_code&quot; ## [31] &quot;util_practice_desc&quot; &quot;source_desc&quot; &quot;commodity_desc&quot; ## [34] &quot;country_name&quot; &quot;prodn_practice_desc&quot; &quot;location_desc&quot; ## [37] &quot;begin_code&quot; &quot;zip_5&quot; &quot;sector_desc&quot; # Keep only the yearly prices corn.annual &lt;- filter(corn, reference_period_desc == &quot;YEAR&quot;) Next, we would like to keep only the relevant columns. To do so, we can use the select() function to drop all columns except year and Value. # Keep the &quot;year&quot; and &quot;Value&quot; columns corn.annual2 &lt;- select(corn.annual, year, Value) corn.annual2 ## year Value ## 1 2019 3.75 ## 2 2018 3.47 ## 3 2017 3.36 ## 4 2016 3.48 ## 5 2015 3.71 ## 6 2014 4.11 ## 7 2013 6.15 ## 8 2012 6.67 ## 9 2011 6.02 ## 10 2010 3.83 ## 11 2009 3.75 ## 12 2008 4.78 ## 13 2007 3.39 ## 14 2006 2.28 ## 15 2005 1.96 ## 16 2004 2.47 ## 17 2003 2.27 ## 18 2002 2.13 ## 19 2001 1.89 ## 20 2000 1.86 ## 21 1999 1.89 ## 22 1998 2.20 ## 23 1997 2.60 ## 24 1996 3.55 Now, we can declare the year as our time index. corn.ts &lt;- as_tsibble(corn.annual2, index = &quot;year&quot;) corn.ts ## # A tsibble: 24 x 2 [1Y] ## year Value ## &lt;int&gt; &lt;dbl&gt; ## 1 1996 3.55 ## 2 1997 2.6 ## 3 1998 2.2 ## 4 1999 1.89 ## 5 2000 1.86 ## 6 2001 1.89 ## 7 2002 2.13 ## 8 2003 2.27 ## 9 2004 2.47 ## 10 2005 1.96 ## # ℹ 14 more rows Notice now that the corn.ts series is now a tsibble object arranged in chronological order (on the year column). 3.2.2 Pipe Operator You can imagine how cumbersome our code will get as we start to perform multiple operations on our raw dataset. We will need to save the intermediary dataframes along the way. Our variable names could quickly become long and confusing. To get around this, we can use the pipe operator, %&gt;%. This allows us to pass arguments (think intermediary dataframes) from left to right and perform various functions/operations at each stage. For simplicity, we will utilize this function extensively throughout this training module. Revisiting the problem above, we can recreate corn.ts in a single line of code. We will store the results in an aptly named variable, corn.ts.pipe. corn.ts.pipe &lt;- corn %&gt;% filter(reference_period_desc == &quot;YEAR&quot;) %&gt;% select(year, Value) %&gt;% as_tsibble(index = &quot;year&quot;) corn.ts.pipe ## # A tsibble: 24 x 2 [1Y] ## year Value ## &lt;int&gt; &lt;dbl&gt; ## 1 1996 3.55 ## 2 1997 2.6 ## 3 1998 2.2 ## 4 1999 1.89 ## 5 2000 1.86 ## 6 2001 1.89 ## 7 2002 2.13 ## 8 2003 2.27 ## 9 2004 2.47 ## 10 2005 1.96 ## # ℹ 14 more rows If you are skeptical, you can check whether all (pairwise) elements in both tsibble objects are the same: identical(corn.ts, corn.ts.pipe) ## [1] TRUE As a shortcut, you can insert the pipe operator using the following syntax: - Windows: CTRL + SHIFT + M - Mac: Cmd + Shift + M 3.3 Visualizing Time Series Data 3.3.1 Time plot We are ready to create our first time series plot. We will use the autoplot() command from the fpp3 package. For those familiar with the ggplot environment, the syntax is very similar. corn.ts %&gt;% autoplot(Value, col = &quot;blue&quot;) + labs(title = &quot;Annual Corn Prices Received&quot;, y = &quot;$/bu&quot;, x= &quot;Year&quot;, caption = &quot;Source: NASS QuickStat&quot;) + theme_bw() The argument theme_bw() is optional. It was used to change the presentation of the graph and gridlines. You can change yours to other default options such as theme_classic(), theme_minimal() or even a user-defined customized theme. Try removing the + theme_bw() portion of your code to see what the results now look like. Walkthrough Exercise Let us return to the Writing a Query Section. Instead of annual data, get the monthly corn prices. It is easiest to filter rows where freq_desc==\"MONTHLY\" Keep only the year, reference_period_desc, and values column. We will declare the data as a tsibble object. This will require some work though to allow R to recognize we have a yearmonth variable. You can use the paste0 function to first create a variable that combines both the year and reference_period_desc columns. Store your variable as corn.monthly and drop all irrelevant columns. Be sure to use the pipe operator to achieve Tasks 1 – 3 in a single step. Now produce an autoplot of corn.monthly. Be sure to add appropriate labels. Solution corn.monthly &lt;- corn %&gt;% # Keep only the Months filter(freq_desc== &quot;MONTHLY&quot;) %&gt;% # Keep only the year, reference_period_desc, and Value columns select(year, reference_period_desc, Value) %&gt;% # Create a yearmonth object mutate(date = yearmonth(paste0(year, reference_period_desc))) %&gt;% # declare date as index as_tsibble(index = date) %&gt;% # Keep only the date and Value column select(date, Value) corn.monthly %&gt;% autoplot(Value, col = &quot;darkblue&quot;) + labs(title = &quot;Monthly Corn Prices&quot;, y = &quot;$/bu&quot;) + theme_bw() Are you able to identify any unique features in this data? Is it trending for example, do we observe seasonality? etc. How could you forecast this series? In the ensuing sections, we will explore the properties of corn.monthly a bit closer. 3.3.2 Visualizing corn.monthly (further) A researcher might be potentially concerned about seasonality in prices received. We have several graphical tools at our disposal to explore this a bit further. 3.3.2.1 Subseriesplots corn.monthly %&gt;% gg_subseries(Value) + labs(title = &quot;Subseries Plot&quot;, y = &quot;&quot;) + theme_bw() The gg_subseriesplot command creates a plot of our corn price data grouped by month (across all years). The blue lines correspond to each monthly average. From these graphs we do not observe the presence of strong seasonality in the price data. 3.3.2.2 Seasonplots If we would like to see the time plot of the data against the seasons (months) instead, we can use the gg_season command. In fact, this is usually a good way to identify years that were potential outliers. corn.monthly %&gt;% gg_season(Value, labels = &quot;both&quot;) + labs(title = &quot;Seasonal Plot of Corn Prices&quot;) + theme_bw() The year.labels = \"both\" argument adds the year labels to the graph (on both sides) instead of in a legend. It is particularly useful in our case since the colors quickly get confusing with so many years. Adding the argument polar = TRUE to the gg_season function produces a variation using polar coordinates. Adding this option makes the time series axis circular rather than horizontal. corn.monthly %&gt;% gg_season(Value, polar = TRUE, labels = &quot;both&quot;) + labs(title = &quot;Seasonal Plot of Corn Prices&quot;) + theme_bw() In general, the summary of the seasonal plot above matches the autoplot earlier. We observe that: In the earlier periods, the values across months were closer (less volatile) than in later periods. On average, prices between 2010 and 2015 were higher than the remaining periods. 2015 to 2019 saw a temperance of prices, albeit higher than the beginning of the sample. 3.3.2.3 Autocorrelation (ACF) Plot Correlation, as a statistical concept, measures the degree of a linear relationship between two variables. Autocorrelation, on the other hand, measures the linear relationship between a variable and its lagged (past) values. The higher the correlation (positive or negative) between our variable, \\(y_t\\) and its lags \\(y_{t-k}\\) where \\(k = 1, \\ldots, T\\), the closer the correlation coefficient is to \\(\\pm 1\\) corn.monthly %&gt;% ACF(Value, lag_max = 36) %&gt;% autoplot() + labs(title = &quot;ACF: Monthly Corn Prices&quot;) + theme_bw() The value of 0.971 at lag 1 implies that last month’s corn price explains more than 94.2841% of the current corn price.2 The correlation value slowly goes to zero as we go further back in time. This indicates that we have a series with a trend. We will discuss further later. To view the correlation statistic at each lag, you can copy and paste the code below. corn.monthly %&gt;% ACF(Value) ## # A tsibble: 25 x 2 [1M] ## lag acf ## &lt;cf_lag&gt; &lt;dbl&gt; ## 1 1M 0.989 ## 2 2M 0.971 ## 3 3M 0.949 ## 4 4M 0.927 ## 5 5M 0.904 ## 6 6M 0.882 ## 7 7M 0.861 ## 8 8M 0.842 ## 9 9M 0.825 ## 10 10M 0.807 ## # ℹ 15 more rows 3.4 Benchmark Forecasting Methods Given our graph above, how could you go about forecasting the corn prices for the next 3 years (\\(h = 36\\))? Below, we will discuss some of the most basic (benchmark) models that are often considered when doing outlook forecasting. 3.4.1 Mean Method A potential model could be to set our forecast equivalent to the mean of the historical series. # The forecast horizon (h) = 36 or 3 years corn.mean &lt;- corn.monthly %&gt;% #Specify the model and give it a name (Optional) model(meanf = MEAN(Value)) %&gt;% # Specify the horizon forecast(h = &quot;3 years&quot;) corn.mean %&gt;% head() ## # A fable: 6 x 4 [1M] ## # Key: .model [1] ## .model date Value .mean ## &lt;chr&gt; &lt;mth&gt; &lt;dist&gt; &lt;dbl&gt; ## 1 meanf 2020 Jan N(3.2, 1.8) 3.19 ## 2 meanf 2020 Feb N(3.2, 1.8) 3.19 ## 3 meanf 2020 Mar N(3.2, 1.8) 3.19 ## 4 meanf 2020 Apr N(3.2, 1.8) 3.19 ## 5 meanf 2020 May N(3.2, 1.8) 3.19 ## 6 meanf 2020 Jun N(3.2, 1.8) 3.19 You should note that the forecasts produced and stored in corn.mean have prediction intervals assigned to them. In this case, it is unremarkable as there is no true uncertainty in our forecasts since we are making projections at the historical mean of the data. Unsurprisingly, all the forecasts are equal to the mean of the data. mean(corn.monthly$Value) ## [1] 3.192139 We can now visualize the data along with the mean forecasts. corn.mean %&gt;% autoplot(corn.monthly, color = &quot;red&quot;, level = NULL) + theme_bw() The level = NULL argument turns off the prediction Intervals (PI) associated with each point in our forecast. If it were omitted, we have corn.mean %&gt;% autoplot(corn.monthly, color = &quot;red&quot;, size = 1) + labs(title = &quot;Mean Forecast&quot;, subtitle = &quot;Corn (Monthly)&quot;) + theme_bw() 3.4.2 Naïve Method Another useful method could be to set the forecasts equal to the last observed value. # Looking at the last 6 values tail(corn.monthly$Value) ## [1] 4.16 3.93 3.80 3.85 3.68 3.71 #Last value last(corn.monthly$Value) ## [1] 3.71 This is especially true if we believe in the Efficient Market hypothesis and in cases where the market is exceptionally volatile or even mean reverting. # The forecast horizon (h) = 36 or 3 years corn.naive &lt;- corn.monthly %&gt;% model(naive = NAIVE(Value)) %&gt;% forecast(h = &quot;3 years&quot;) corn.naive ## # A fable: 36 x 4 [1M] ## # Key: .model [1] ## .model date Value .mean ## &lt;chr&gt; &lt;mth&gt; &lt;dist&gt; &lt;dbl&gt; ## 1 naive 2020 Jan N(3.7, 0.036) 3.71 ## 2 naive 2020 Feb N(3.7, 0.072) 3.71 ## 3 naive 2020 Mar N(3.7, 0.11) 3.71 ## 4 naive 2020 Apr N(3.7, 0.14) 3.71 ## 5 naive 2020 May N(3.7, 0.18) 3.71 ## 6 naive 2020 Jun N(3.7, 0.22) 3.71 ## 7 naive 2020 Jul N(3.7, 0.25) 3.71 ## 8 naive 2020 Aug N(3.7, 0.29) 3.71 ## 9 naive 2020 Sep N(3.7, 0.32) 3.71 ## 10 naive 2020 Oct N(3.7, 0.36) 3.71 ## # ℹ 26 more rows Notice here that the forecasts for all future periods are set to the last observed value, 3.71 Visualizing the data and the forecasts # plot the forecasts stored in corn.naive corn.naive %&gt;% autoplot(corn.monthly, color = &quot;purple&quot;, size = 1) + labs(title = &quot;Naïve Forecast&quot;, subtitle = &quot;Corn (Monthly)&quot;) + theme_bw() Notice that despite setting the forecasts all equal to the last value, the uncertainty around our predictions (as shown by the PIs) is increasing as we go further into the future. 3.4.3 Seasonal Naïve Method If we assume that the series displays seasonality, we could use a seasonal naïve method. The forecast for a given season (say January 2020 and February 2020) is equal to the last value observed for that same season (January 2019 and February 2019, respectively, in this case). # The forecast horizon (h) = 36 or 3 years corn.snaive &lt;- corn.monthly %&gt;% model(snaive = SNAIVE(Value)) %&gt;% forecast(h = &quot;3 years&quot;) corn.snaive ## # A fable: 36 x 4 [1M] ## # Key: .model [1] ## .model date Value .mean ## &lt;chr&gt; &lt;mth&gt; &lt;dist&gt; &lt;dbl&gt; ## 1 snaive 2020 Jan N(3.6, 0.81) 3.56 ## 2 snaive 2020 Feb N(3.6, 0.81) 3.6 ## 3 snaive 2020 Mar N(3.6, 0.81) 3.61 ## 4 snaive 2020 Apr N(3.5, 0.81) 3.53 ## 5 snaive 2020 May N(3.6, 0.81) 3.63 ## 6 snaive 2020 Jun N(4, 0.81) 3.98 ## 7 snaive 2020 Jul N(4.2, 0.81) 4.16 ## 8 snaive 2020 Aug N(3.9, 0.81) 3.93 ## 9 snaive 2020 Sep N(3.8, 0.81) 3.8 ## 10 snaive 2020 Oct N(3.8, 0.81) 3.85 ## # ℹ 26 more rows # plot the forecasts stored in corn.snaive corn.snaive %&gt;% autoplot(corn.monthly, color = &quot;darkgreen&quot;, size = 1) + labs(title = &quot;Seasonal Naïve Forecast&quot;, subtitle = &quot;Corn (Monthly)&quot;) + theme_bw() Notice that the pattern (over a year) repeats itself into the future. This is the nature of the seasonal naive model. All January values will be assigned the last observed January value. You can view the last 12 values (since we ended the dataset in December 2019) to validate this: tail(corn.monthly,12) ## # A tsibble: 12 x 2 [1M] ## date Value ## &lt;mth&gt; &lt;dbl&gt; ## 1 2019 Jan 3.56 ## 2 2019 Feb 3.6 ## 3 2019 Mar 3.61 ## 4 2019 Apr 3.53 ## 5 2019 May 3.63 ## 6 2019 Jun 3.98 ## 7 2019 Jul 4.16 ## 8 2019 Aug 3.93 ## 9 2019 Sep 3.8 ## 10 2019 Oct 3.85 ## 11 2019 Nov 3.68 ## 12 2019 Dec 3.71 3.4.4 Drift Method In this case, we assign the forecasts as the last value plus the average change over the sample. This is equivalent to drawing a straight line between the first and last observations and extrapolating out into the future. This is commonly referred to as the RW (Naïve) model with drift. # The forecast horizon (h) = 36 or 3 years corn.drift &lt;- corn.monthly %&gt;% model( drift = RW(Value ~ drift ())) %&gt;% forecast(h = 36) corn.drift ## # A fable: 36 x 4 [1M] ## # Key: .model [1] ## .model date Value .mean ## &lt;chr&gt; &lt;mth&gt; &lt;dist&gt; &lt;dbl&gt; ## 1 drift 2020 Jan N(3.7, 0.036) 3.71 ## 2 drift 2020 Feb N(3.7, 0.073) 3.72 ## 3 drift 2020 Mar N(3.7, 0.11) 3.72 ## 4 drift 2020 Apr N(3.7, 0.15) 3.73 ## 5 drift 2020 May N(3.7, 0.18) 3.73 ## 6 drift 2020 Jun N(3.7, 0.22) 3.73 ## 7 drift 2020 Jul N(3.7, 0.26) 3.74 ## 8 drift 2020 Aug N(3.7, 0.3) 3.74 ## 9 drift 2020 Sep N(3.7, 0.33) 3.75 ## 10 drift 2020 Oct N(3.7, 0.37) 3.75 ## # ℹ 26 more rows # plot the forecasts stored in corn.drift corn.drift %&gt;% autoplot(corn.monthly, color = &quot;cornflowerblue&quot;, size = 1) + labs(title = &quot;Randow Walk with Drift Forecast&quot;, subtitle = &quot;Corn (Monthly)&quot;) + theme_bw() 3.4.5 Visualing all Forecasts Like much of coding in R, there are several ways to accomplish a given task. We will take the simplest path and first save all 4 models in a single fable. models.corn &lt;- corn.monthly %&gt;% model( mean = MEAN(Value), naive = RW(Value), snaive = SNAIVE(Value), drift = RW(Value ~ drift()) ) %&gt;% forecast(h = &quot;3 years&quot;) models.corn ## # A fable: 144 x 4 [1M] ## # Key: .model [4] ## .model date Value .mean ## &lt;chr&gt; &lt;mth&gt; &lt;dist&gt; &lt;dbl&gt; ## 1 mean 2020 Jan N(3.2, 1.8) 3.19 ## 2 mean 2020 Feb N(3.2, 1.8) 3.19 ## 3 mean 2020 Mar N(3.2, 1.8) 3.19 ## 4 mean 2020 Apr N(3.2, 1.8) 3.19 ## 5 mean 2020 May N(3.2, 1.8) 3.19 ## 6 mean 2020 Jun N(3.2, 1.8) 3.19 ## 7 mean 2020 Jul N(3.2, 1.8) 3.19 ## 8 mean 2020 Aug N(3.2, 1.8) 3.19 ## 9 mean 2020 Sep N(3.2, 1.8) 3.19 ## 10 mean 2020 Oct N(3.2, 1.8) 3.19 ## # ℹ 134 more rows Unlike the codes earlier, you will notice I used the RW function to estimate the Naïve model instead of the NAIVE function. Both functions are equivalent. RW is more flexible however, as it allows us to add the drift term. You might find it best to turn off the PIs for this plot. Otherwise, our graph will be too busy. models.corn %&gt;% autoplot(corn.monthly, level = NULL, size = 0.8) + labs(title = &quot;Forecasts - Corn (Monthly)&quot;) + theme_bw() The emphasis of this module is not to perform model comparisons. We will have a module dedicated to that later. Instead, this module is centered on improving your competence and familiarity with typical models and the associated R syntax. Exercise Using the tidyUSDA package, import price data (at the National Level) for a commodity of your choice from 2000 – 2019. Following the data manipulation techniques earlier in this module, obtain the monthly series declared as a tsibble object. present a time series plot of the data. produce a subseriesplot and seasonplot of your data. produce the ACF plot of the data. what do you observe from parts ii – iv. produce and plot the 4 Benchmark forecasts of your data. Use a forecast horizon of 2 years (h = 24). 3.4.6 Exponential Smoothing There are many ways to do exponential smoothing. The general idea is always to have a declining weight given to observations. The more recent an observation, the more important it should be to our forecasting (and hence a higher weight). 3.4.6.1 Simple exponential Smoothing This method is suitable for forecasting data with no clear trend or seasonal pattern. For a moment, let us ignore the trend present in the our corn prices data. We could estimate the simple exponential smoothing model forecasts as follows corn.ses &lt;- corn.monthly %&gt;% model(ses = ETS(Value ~ error(&quot;A&quot;)+ trend(&quot;N&quot;) + season(&quot;N&quot;))) You can view the stored model fit (in-sample) using the augment function corn.ses %&gt;% augment() ## # A tsibble: 360 x 6 [1M] ## # Key: .model [1] ## .model date Value .fitted .resid .innov ## &lt;chr&gt; &lt;mth&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ses 1990 Jan 2.31 2.31 0.000556 0.000556 ## 2 ses 1990 Feb 2.32 2.31 0.0100 0.0100 ## 3 ses 1990 Mar 2.37 2.32 0.0500 0.0500 ## 4 ses 1990 Apr 2.51 2.37 0.140 0.140 ## 5 ses 1990 May 2.62 2.51 0.110 0.110 ## 6 ses 1990 Jun 2.63 2.62 0.0100 0.0100 ## 7 ses 1990 Jul 2.62 2.63 -0.0100 -0.0100 ## 8 ses 1990 Aug 2.51 2.62 -0.110 -0.110 ## 9 ses 1990 Sep 2.32 2.51 -0.190 -0.190 ## 10 ses 1990 Oct 2.19 2.32 -0.130 -0.130 ## # ℹ 350 more rows Producing our forecasts as before: corn.ses %&gt;% forecast(h = &quot;3 years&quot;) ## # A fable: 36 x 4 [1M] ## # Key: .model [1] ## .model date Value .mean ## &lt;chr&gt; &lt;mth&gt; &lt;dist&gt; &lt;dbl&gt; ## 1 ses 2020 Jan N(3.7, 0.036) 3.71 ## 2 ses 2020 Feb N(3.7, 0.072) 3.71 ## 3 ses 2020 Mar N(3.7, 0.11) 3.71 ## 4 ses 2020 Apr N(3.7, 0.14) 3.71 ## 5 ses 2020 May N(3.7, 0.18) 3.71 ## 6 ses 2020 Jun N(3.7, 0.22) 3.71 ## 7 ses 2020 Jul N(3.7, 0.25) 3.71 ## 8 ses 2020 Aug N(3.7, 0.29) 3.71 ## 9 ses 2020 Sep N(3.7, 0.33) 3.71 ## 10 ses 2020 Oct N(3.7, 0.36) 3.71 ## # ℹ 26 more rows You will quickly notice that the point estimates of our forecasts are flat over the forecast horizon. However, the uncertainty of that estimate will be increasing over time. That is, the prediction interval (PI) is increasing. We can visualize the information stored in corn.ses using the autoplot command. corn.ses %&gt;% forecast(h = &quot;3 years&quot;) %&gt;% autoplot(corn.monthly, color = &quot;goldenrod&quot;, size = 1) + labs(title = &quot;Simple Exponential Smoothing&quot;, subtitle = &quot;Corn (Monthly)&quot;) + theme_bw() We might need to consider other exponential smoothing techniques that could account for a potential trend. ETS Taxonomy Exponential smoothing methods are classified by their “Trend” and “Seasonal” components, \\(T\\) &amp; \\(S\\), respectively. Classifications of exponetntail smoothing methods Error: Additive (“A”) or Multiplicative (“M”) Trend: None (“N”), additive (“A”), multiplicative (“M”), or damped (“Ad” or “Md”) Season: None (“N”), additive (“A”), or multiplicative (“M”) We will suppress the results here to conserve on space.↩︎ The correlation stats squared.↩︎ "],["time-series-patterns.html", "Module 4 Time Series Patterns 4.1 Cold Storage Data - Pork Exercise Annualized data 4.2 Moving Averages Model Deviation (Error) Final Words: Moving Averages 4.3 Simple Exponential Smoothing (Again) 4.4 Exponential Smoothing Adjusted for Trend &amp; Seasonality 4.5 Time Series Regression Analysis 4.6 Accounting for Seasonality and Trend 4.7 Visualizing the model fits 4.8 Autoregressive Models Exercise", " Module 4 Time Series Patterns So far, we have focused on pulling and visualizing data. However, we have not spoken about the Patterns that might exist and just what we look for in time series data. Trend \\((T_t)\\) pattern exists when there is a long-term increase or decrease in the data. The trend may be produced, for example, by consistent population change, inflation, technological change, and productivity increases. Cyclical \\((C_t)\\) series of wavelike pattern exists when data exhibit rises and falls that are not of fixed period (duration usually of at least 2 years). Changing economic conditions generally produce cycles. In practice, cycles are often difficult to identify and are frequently regarded as part of the trend. In this case, the underlying general growth (or decline) component is called the trend-cycle. Seasonal \\((S_t)\\) pattern exists when a series is influenced by seasonal factors (e.g., the quarter of the year, the month, or day of the week). Seasonal variation refers to a more or less stable pattern of change that appears annually and repeats itself year after year. Seasonal patterns occur because of the influence of the weather or because of calendar-related events such as school vacations and national holidays. Random/Irregular \\((I_t)\\) - consists of unpredictable or random fluctuations. These fluctuations are the result of a myriad of events that individually may not be particularly important but whose combined effect could be large. Differences between seasonal and cyclic patterns Seasonal pattern constant length; cyclic pattern variable length. Average length of cycle longer than length of seasonal pattern. - Magnitude of cycle more variable than magnitude of seasonal pattern 4.1 Cold Storage Data - Pork Let us shift focus to pulling monthly Cold Storage values for Pork (1983:2020). You will need your key from earlier. I will assume yours is stored using the keyring package. # Step 1: Supply your Key key &lt;- keyring::key_get(&quot;tidyusda&quot;) # Step 2: Use the API to pull Pork Cold Storage pork &lt;- tidyUSDA::getQuickstat( key = key, program = &quot;SURVEY&quot;, sector = &quot;ANIMALS &amp; PRODUCTS&quot;, group = &quot;LIVESTOCK&quot;, commodity = &quot;PORK&quot;, category = &quot;STOCKS&quot;, data_item = &quot;PORK, COLD STORAGE, FROZEN - STOCKS, MEASURED IN LB&quot;, domain = &quot;TOTAL&quot;, geographic_level = &quot;NATIONAL&quot;, state = &quot;US TOTAL&quot;, year = as.character(1983:2020) ) # Step 3 &amp; 4: Keep only the relevant columns and declare as tsibble object pork.ts &lt;- pork %&gt;% # Convert the year + month index to a yearmonth object mutate(date = yearmonth(paste(year,begin_code)), # divide Value by 1 million and save over original column Value = Value/1000000) %&gt;% select(date, Value) %&gt;% as_tsibble(index = date) pork.ts ## # A tsibble: 456 x 2 [1M] ## date Value ## &lt;mth&gt; &lt;dbl&gt; ## 1 1983 Jan 224. ## 2 1983 Feb 216. ## 3 1983 Mar 235. ## 4 1983 Apr 273. ## 5 1983 May 293. ## 6 1983 Jun 280. ## 7 1983 Jul 253. ## 8 1983 Aug 214. ## 9 1983 Sep 210. ## 10 1983 Oct 240. ## # ℹ 446 more rows # Step 5: Produce a time plot pork.ts %&gt;% autoplot(Value, color = &quot;darkred&quot;) + labs(title = &quot;Pork Cold Storage&quot;, subtitle = &quot;(Million pounds)&quot;) + theme_bw() Exercise Can you use the functions we covered earlier to explore the seasonal properties of this data? What would you conclude regarding potential seasonality and/or trend. Annualized data We might be interested in the annual mean cold storage instead. Again, there are several ways to do this but we will stick with the tidyverse conventions. pork.annual &lt;- pork.ts %&gt;% # Group observations on year index index_by(year = year(date)) %&gt;% # Compute the annual means summarise(Value = mean(Value)) pork.annual ## # A tsibble: 38 x 2 [1Y] ## year Value ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1983 253. ## 2 1984 323. ## 3 1985 312. ## 4 1986 228. ## 5 1987 215. ## 6 1988 337. ## 7 1989 343. ## 8 1990 267. ## 9 1991 297. ## 10 1992 325. ## # ℹ 28 more rows Now, you can produce a plot of the annual series. pork.annual %&gt;% autoplot(Value, color = &quot;darkgreen&quot;) + labs(title = &quot;Annual Pork Cold Storage&quot;, subtitle = &quot;Million pounds&quot;, x = &quot;Year&quot;, caption = &quot;Source: NASS QuickStat&quot;) + theme_bw() 4.2 Moving Averages Sometimes it could be helpful to see where the current series is relative to its historical average. Moving averages can be helpful in achieving this. More formally, moving averages allow us to extract the long-term trend (and cycle) in the data. Returning to our annual pork cold storage series, pork.annual, we can generate a centered 3-year moving averages. sma3 &lt;- pork.annual %&gt;% mutate( `3-MA` = slider::slide_dbl(Value, mean, .before = 1, .after = 1, .complete = TRUE) ) sma3 ## # A tsibble: 38 x 3 [1Y] ## year Value `3-MA` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1983 253. NA ## 2 1984 323. 296. ## 3 1985 312. 288. ## 4 1986 228. 252. ## 5 1987 215. 260. ## 6 1988 337. 298. ## 7 1989 343. 316. ## 8 1990 267. 302. ## 9 1991 297. 296. ## 10 1992 325. 319. ## # ℹ 28 more rows Now we can produce a plot of the annual series and the simple moving average series. sma3 %&gt;% autoplot(Value) + autolayer(sma3,`3-MA`, color = &quot;darkorange&quot;) + labs(title = &quot;Pork Cold Storage&quot;, subtitle = &quot;MA (3)&quot;) + theme_bw() The trend-cycle component computed by the simple moving average is much smoother than the data itself. In fact, the choice of the “window” or number of data points used for smoothing will play a role in how smooth, or jagged our trend-cycle is. A larger order means smoother curves as it is less sensitive to extreme events during any particular period. Repeating for multiple orders: smas &lt;- pork.annual %&gt;% mutate( `3-MA` = slider::slide_dbl(Value, mean, .before = 1, .after = 1, .complete = TRUE), `5-MA` = slider::slide_dbl(Value, mean, .before = 2, .after = 2, .complete = TRUE), `7-MA` = slider::slide_dbl(Value, mean, .before = 3, .after = 3, .complete = TRUE) ) smas ## # A tsibble: 38 x 5 [1Y] ## year Value `3-MA` `5-MA` `7-MA` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1983 253. NA NA NA ## 2 1984 323. 296. NA NA ## 3 1985 312. 288. 266. NA ## 4 1986 228. 252. 283. 287. ## 5 1987 215. 260. 287. 289. ## 6 1988 337. 298. 278. 286. ## 7 1989 343. 316. 292. 287. ## 8 1990 267. 302. 314. 303. ## 9 1991 297. 296. 313. 327. ## 10 1992 325. 319. 321. 333. ## # ℹ 28 more rows It is not coincidental that all the orders used here are odd. If we use an even number (say the case of working with quarterly data), we are required to do double smoothing. We leave this as an exercise for the interested reader. Visualizing the full model results smas %&gt;% pivot_longer(-c(year,Value), names_to = &quot;Series&quot;, values_to = &quot;mean&quot;) %&gt;% ggplot(aes(x = year, y = mean, color = Series)) + geom_line() + geom_line(aes(x = year, y = Value), color = &quot;black&quot;) + facet_wrap(~Series, ncol = 2) + guides(color = &quot;none&quot;) + theme_bw() Model Deviation (Error) If we were interested in visualizing how often our actual data deviates from the trend cycle, we could calculate the difference between the two. sma3 %&gt;% mutate(error = Value - `3-MA`) %&gt;% autoplot(error) + geom_point() + geom_abline(slope = 0, lty = &quot;dashed&quot;, color = &quot;red&quot;) + labs(title = &quot;Forecast Errors - MA(3)&quot;) + theme_bw() ## Warning: Removed 2 rows containing missing values (`geom_line()`). ## Warning: Removed 2 rows containing missing values (`geom_point()`). Final Words: Moving Averages The forecast will lag turning points, if it captures them at all. There is a tendency to oversmooth at high orders. In general, MAs can be used for forecasting only in series that lack seasonality and trend. There are a few popular methods for removing trends (de-trending) and removing seasonality (deseasonalizing) from a series: Advanced exponential smoothing methods, Regression models, and Differencing. In the case of the moving averages, we assigned equal weights to the most recent observations as well as those far into the past. We can quickly see how this becomes problematic when forecasting data with structural breaks (changes drastically over time) etc. 4.3 Simple Exponential Smoothing (Again) So far, we learned that this method is suitable for forecasting data with no clear trend or seasonal pattern. Since the simple exponential smoothing model does not account for a potential trend nor seasonality, we saw that the out of sample forecast will be a flat line. Thankfully, there are other exponential smoothing models that account for either, and both, patterns. 4.3.1 Exponential Smoothing Adjusted for Trend Holt’s Method allows for evolving local linear trends in a time series can be used to generate forecasts Advantage: flexible to track changing in level and trend pork.annual %&gt;% model(holt = ETS(Value ~ error(&quot;A&quot;) + trend(&quot;A&quot;) + season(&quot;N&quot;))) %&gt;% forecast(h = &quot;15years&quot;) %&gt;% autoplot(pork.annual) + labs(title = &quot;Pork Cold Storage (Annual)&quot;, subtitle = &quot;Holt&#39;s Model&quot;) + theme_bw() Our choice of 15 years is strictly for illustration purposes. This is intended to help with understanding the disadvantages of a standard Holt model and for comparison with the damped trend, below. Holt’s Linear Trend Method with a Damped Trend The forecasts generated by Holt’s linear method display a constant trend (increasing or decreasing) indefinitely into the future. Empirical evidence indicates that these methods tend to over-forecast, especially for longer forecast horizons. pork.annual %&gt;% model(holt_damped = ETS(Value ~ error(&quot;A&quot;) + trend(&quot;Ad&quot;) + season(&quot;N&quot;))) %&gt;% forecast(h = &quot;15years&quot;) %&gt;% autoplot(pork.annual) + labs(title = &quot;Pork Cold Storage (Annual)&quot;, subtitle = &quot;Holt&#39;s Model with Damped Trend&quot;) + theme_bw() 4.4 Exponential Smoothing Adjusted for Trend &amp; Seasonality Holt-Winter’s Exponential Smoothing Methods Holt-Winter’s method provides an easy way to account for seasonality when data have a seasonal pattern. We can now shift focus to the monthly cold storage data stored earlier, pork.ts. pork.ts %&gt;% model(holtwinters = ETS(Value ~ error(&quot;A&quot;) + trend(&quot;A&quot;) + season(&quot;A&quot;))) %&gt;% forecast(h = &quot;2years&quot;) %&gt;% autoplot(pork.ts, size = 1) + labs(title = &quot;Pork Cold Storage (Monthly)&quot;, subtitle = &quot;Holt-Winter&#39;s Model&quot;) + theme_bw() 4.5 Time Series Regression Analysis For this section, we will maintain our focus on the monthly pork cold storage series. Declaring our series as a tsbibble object earlier has a number of advantages. For example, it removes the need to manually create some of the variables we will need in this section. In particular, we can estimate regresssions using trends and seasonal dummies using the trend and seasons command in the tslm function. 4.5.1 Accounting for (Linear) Trends We can introduce a trend by including \\(x_t = t\\) as a regressor \\[\\begin{equation}\\tag{1} y_t = \\beta_0 + \\beta_1 t + \\varepsilon_t \\end{equation}\\] where \\(t = 1, 2, \\ldots, T\\). Here \\(T\\) is the total number of years in the dataset. We can estimate the linear trend model as follows: model1 &lt;- pork.ts %&gt;% model(TSLM(Value ~ trend())) #View estimated parameters model1 %&gt;% tidy() ## # A tibble: 2 × 6 ## .model term estimate std.error statistic p.value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 TSLM(Value ~ trend()) (Intercept) 255. 5.88 43.3 2.16e-163 ## 2 TSLM(Value ~ trend()) trend() 0.811 0.0223 36.4 1.31e-136 In the codes above, we estimate the regression implied by Equation (1) and store it as model1. Next, we used the tidy() function to extract the stored regression results. The value on the trend term implies that, on average, pork cold storage increases by 0.811 million pounds per month. Digression: How would we account for a potential quadratic trend trend model? Our model would look like \\[y_t = \\beta_0 + \\beta_1 t + \\beta_2 t^2 + \\varepsilon_t\\] We can perform mathematical manipulations in the time series linear model (TSLM) function using I() . Alternatively, we could create a squared trend variable manually. The former can be coded quickly as: model.sqr &lt;- pork.ts %&gt;% model(TSLM(Value ~ trend() + I(trend()^2))) model.sqr %&gt;% tidy() 4.5.2 Accounting for Seasonality We can test/account for seasonality in the monthly series by including monthly dummies using the season() argument in the TSLM command. What is a Dummy? If a categorical variable takes only two values (e.g., ‘Yes’ or ‘No’), then we can construct a numerical variable taking value 1 if yes and 0 if no, for example. This is called a dummy variable. Suppose we have quarterly retail sales data and suspect that there might be seasonality in our data (e.g. Q4 might have unusually high sales figures since we have Thanksgiving, Black Friday, Cyber Monday, and Christmas in Nov. &amp; Dec.) \\(Q_{1,t}\\) \\(Q_{2,t}\\) \\(Q_{3,t}\\) 2000 Q1 1 0 0 2000 Q2 0 1 0 2000 Q3 0 0 1 2000 Q4 0 0 0 2001 Q1 1 0 0 2001 Q2 0 1 0 2001 Q3 0 0 1 2001 Q4 0 0 0 Caution: When estimating our regressions, we must leave out one of the dummy variables. The omitted dummy is referred to as the base/reference group. For example, in our monthly series, we will omit season()year1 or January. The value on the remaining monthly dummies are all relative to January. The seasonal model is estimated as \\[\\begin{equation}\\tag{2} y_t = \\beta_0 + \\beta_1 \\underset{season()year2}{Feb} + \\beta_2 \\underset{season()year3}{March} + \\ldots + \\beta_{11} \\underset{season()year4}{Dec} + \\varepsilon_t \\end{equation}\\] where \\(\\text{Feb}, \\text{March}, \\ldots, \\text{Dec}\\) are monthly dummies that take a value of 1 if the observation corresponds to that month and \\(0\\) otherwise. model2 &lt;- pork.ts %&gt;% model(TSLM(Value ~ season())) model2 %&gt;% report() ## Series: Value ## Model: TSLM ## ## Residuals: ## Min 1Q Median 3Q Max ## -273.96 -96.92 14.53 95.63 248.37 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 449.011 19.766 22.716 &lt;2e-16 *** ## season()year2 20.362 27.954 0.728 0.467 ## season()year3 20.293 27.954 0.726 0.468 ## season()year4 42.715 27.954 1.528 0.127 ## season()year5 25.960 27.954 0.929 0.354 ## season()year6 -7.338 27.954 -0.263 0.793 ## season()year7 -28.863 27.954 -1.033 0.302 ## season()year8 -43.625 27.954 -1.561 0.119 ## season()year9 -33.663 27.954 -1.204 0.229 ## season()year10 -27.294 27.954 -0.976 0.329 ## season()year11 -39.000 27.954 -1.395 0.164 ## season()year12 -39.311 27.954 -1.406 0.160 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 121.8 on 444 degrees of freedom ## Multiple R-squared: 0.05479, Adjusted R-squared: 0.03137 ## F-statistic: 2.34 on 11 and 444 DF, p-value: 0.0083218 Our regression results suggest that, on average, pork cold storage for February is 20.362 million pounds higher than January. However, June to December are persistently lower than January (looking at the sign here). The mean value for January is represented by the intercept. The average cold storage for January is 449.011 million pounds. If we would like to determine the mean values for the remaining months, we need only add the intercept to the value of estimate for that month. For example, the mean pork cold storage for August would be 405.386 million pounds. 4.6 Accounting for Seasonality and Trend \\[\\begin{equation}\\tag{3} y_t = \\beta_0 + \\beta_1 Feb + \\beta_2 March + \\ldots + \\beta_{11} Dec + \\beta_{12} t + \\varepsilon_t \\end{equation}\\] We estimate Equation (3) by combining the 2 code chunks earlier. model3 &lt;- pork.ts %&gt;% model(TSLM(Value ~ season() + trend())) model3 %&gt;% report() ## Series: Value ## Model: TSLM ## ## Residuals: ## Min 1Q Median 3Q Max ## -188.146 -34.757 1.315 37.754 134.854 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 267.09181 9.92159 26.920 &lt; 2e-16 *** ## season()year2 19.54583 12.60390 1.551 0.121670 ## season()year3 18.66149 12.60395 1.481 0.139422 ## season()year4 40.26716 12.60402 3.195 0.001499 ** ## season()year5 22.69638 12.60413 1.801 0.072429 . ## season()year6 -11.41700 12.60427 -0.906 0.365532 ## season()year7 -33.75747 12.60443 -2.678 0.007677 ** ## season()year8 -49.33543 12.60463 -3.914 0.000105 *** ## season()year9 -40.18887 12.60486 -3.188 0.001532 ** ## season()year10 -34.63588 12.60512 -2.748 0.006245 ** ## season()year11 -47.15766 12.60540 -3.741 0.000207 *** ## season()year12 -48.28471 12.60572 -3.830 0.000146 *** ## trend() 0.81578 0.01955 41.725 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 54.94 on 443 degrees of freedom ## Multiple R-squared: 0.8083, Adjusted R-squared: 0.8031 ## F-statistic: 155.6 on 12 and 443 DF, p-value: &lt; 2.22e-16 4.7 Visualizing the model fits We can use the augment command to see all the elements stored in our model fits earlier. model1 %&gt;% augment() ## # A tsibble: 456 x 6 [1M] ## # Key: .model [1] ## .model date Value .fitted .resid .innov ## &lt;chr&gt; &lt;mth&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 TSLM(Value ~ trend()) 1983 Jan 224. 255. -31.3 -31.3 ## 2 TSLM(Value ~ trend()) 1983 Feb 216. 256. -40.4 -40.4 ## 3 TSLM(Value ~ trend()) 1983 Mar 235. 257. -22.3 -22.3 ## 4 TSLM(Value ~ trend()) 1983 Apr 273. 258. 14.8 14.8 ## 5 TSLM(Value ~ trend()) 1983 May 293. 259. 34.3 34.3 ## 6 TSLM(Value ~ trend()) 1983 Jun 280. 260. 20.9 20.9 ## 7 TSLM(Value ~ trend()) 1983 Jul 253. 260. -7.33 -7.33 ## 8 TSLM(Value ~ trend()) 1983 Aug 214. 261. -47.1 -47.1 ## 9 TSLM(Value ~ trend()) 1983 Sep 210. 262. -52.0 -52.0 ## 10 TSLM(Value ~ trend()) 1983 Oct 240. 263. -22.7 -22.7 ## # ℹ 446 more rows It might prove helpful to visualize a plot of the actual data against the fitted values. We can therefore return to our select function from earlier. model1 %&gt;% augment() %&gt;% #plot the actual series ggplot(aes(x = date, y = Value)) + geom_line() + # Add fitted values column geom_line(aes(y = .fitted),color = &quot;darkblue&quot;, size = 1) + labs(title = &quot;Forecasts - Trend Model&quot;) + theme_bw() ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. Let us merge all the codes above to extract the fitted values of our three models and produce a single plot that allows us to visualize the data and the fits of all the models. full.mod &lt;- pork.ts %&gt;% model(trend = TSLM(Value ~ trend()), season = TSLM(Value ~ season()), trend_season = TSLM(Value ~ trend() + season())) full.mod %&gt;% augment() ## # A tsibble: 1,368 x 6 [1M] ## # Key: .model [3] ## .model date Value .fitted .resid .innov ## &lt;chr&gt; &lt;mth&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 trend 1983 Jan 224. 255. -31.3 -31.3 ## 2 trend 1983 Feb 216. 256. -40.4 -40.4 ## 3 trend 1983 Mar 235. 257. -22.3 -22.3 ## 4 trend 1983 Apr 273. 258. 14.8 14.8 ## 5 trend 1983 May 293. 259. 34.3 34.3 ## 6 trend 1983 Jun 280. 260. 20.9 20.9 ## 7 trend 1983 Jul 253. 260. -7.33 -7.33 ## 8 trend 1983 Aug 214. 261. -47.1 -47.1 ## 9 trend 1983 Sep 210. 262. -52.0 -52.0 ## 10 trend 1983 Oct 240. 263. -22.7 -22.7 ## # ℹ 1,358 more rows full.mod %&gt;% augment() %&gt;% ggplot(aes(x = date, y = Value)) + geom_line() + geom_line(aes(y = .fitted, color = .model), size = 0.7) + labs(title = &quot;Model Fits&quot;, subtitle = &quot;Pork Cold Storage&quot;) + theme_bw() Without formal testing (just from eyeballing the graph), it appears that the Trend+seasonal dummies model does the best job of forecasting the monthly series. We will cover formal testing in a later module. We can use the forecast function to create out-of-sample forecasts of our 3 models. It is worthwhile to note that the trend value and dummies are always known into the future so we will not have a problem with unknown data at the time of forecasting. Our forecast will become a lot more complicated when we have other economic variables on the right hand side. We will also need forecasts of their future values, before we are able to forecast our true variable of interest. pork.forecast &lt;- full.mod %&gt;% forecast(h = &quot;2 year&quot;) pork.forecast ## # A fable: 72 x 4 [1M] ## # Key: .model [3] ## .model date Value .mean ## &lt;chr&gt; &lt;mth&gt; &lt;dist&gt; &lt;dbl&gt; ## 1 trend 2021 Jan N(625, 3959) 625. ## 2 trend 2021 Feb N(626, 3960) 626. ## 3 trend 2021 Mar N(627, 3960) 627. ## 4 trend 2021 Apr N(628, 3960) 628. ## 5 trend 2021 May N(628, 3960) 628. ## 6 trend 2021 Jun N(629, 3961) 629. ## 7 trend 2021 Jul N(630, 3961) 630. ## 8 trend 2021 Aug N(631, 3961) 631. ## 9 trend 2021 Sep N(632, 3961) 632. ## 10 trend 2021 Oct N(632, 3961) 632. ## # ℹ 62 more rows pork.forecast %&gt;% autoplot(pork.ts, level = NULL, size = 0.8) + labs(title = &quot;Forecasted Pork cold Storage&quot;, subtitle = &quot;Next 24 Months&quot;) + guides(color = guide_legend(title = &quot;Forecast&quot;)) + theme_bw() 4.8 Autoregressive Models 4.8.1 AR(1) model Sometimes it might be useful to use past values of \\(y\\) to help in predicting the \\(y\\)’s future values. Such models are referred to as Auto-regressive lag models. For example: The price in the next period might be a function of the price observed today. \\[p_t = \\alpha + \\beta p_{t-1} + \\varepsilon_t\\] where \\(p_t\\) could refer to prices (value) of our frozen pork stock. Since this model includes only 1 lag of the \\(y\\) variable, this is referred to as an AR(1) model. We will use the lag function to quickly create our lagged variables. pork.l1 &lt;- pork.ts %&gt;% mutate(l.pork = lag(Value,1)) pork.l1 ## # A tsibble: 456 x 3 [1M] ## date Value l.pork ## &lt;mth&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1983 Jan 224. NA ## 2 1983 Feb 216. 224. ## 3 1983 Mar 235. 216. ## 4 1983 Apr 273. 235. ## 5 1983 May 293. 273. ## 6 1983 Jun 280. 293. ## 7 1983 Jul 253. 280. ## 8 1983 Aug 214. 253. ## 9 1983 Sep 210. 214. ## 10 1983 Oct 240. 210. ## # ℹ 446 more rows Now to estimate the equation above mod.ar1 &lt;- pork.l1 %&gt;% model(ar1 = TSLM(Value ~ l.pork)) mod.ar1 %&gt;% report() ## Series: Value ## Model: TSLM ## ## Residuals: ## Min 1Q Median 3Q Max ## -137.352 -19.121 -2.019 18.490 116.539 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 16.7666 5.5298 3.032 0.00257 ** ## l.pork 0.9628 0.0121 79.573 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 31.95 on 453 degrees of freedom ## Multiple R-squared: 0.9332, Adjusted R-squared: 0.9331 ## F-statistic: 6332 on 1 and 453 DF, p-value: &lt; 2.22e-16 Visualizing the AR(1) model fit We can use the autoplot to visualize the fit of the AR(1) model. mod.ar1 %&gt;% augment() %&gt;% ggplot(aes(x= date, y = Value)) + geom_line() + geom_line(aes(y = .fitted), color = &quot;red&quot;) + labs(title = &quot;AR(1) Model Fit&quot;) + theme_bw() ## Warning: Removed 1 row containing missing values (`geom_line()`). At the end of your sample, you will be able to estimate a 1-step ahead out-of-sample forecast as all values are known. As you move beyond that single period, you will not be able to forecast without telling R what your guess of the new data will be. You could circumvent this issue using scenario based forecasts. That is however beyond the scope of this module. 4.8.2 AR(p) model We could generalize to an AR(p) model. \\[\\begin{align*} y_t &amp;= \\alpha + \\beta_1 y_{t-1} + \\beta_2 y_{t-2} + \\ldots + \\beta_p y_{t-p} + \\varepsilon_t\\\\ \\longrightarrow y_t &amp;= \\alpha + \\beta_i \\sum_{i = 1}^{p} y_{t-p} + \\varepsilon_t \\end{align*}\\] The choice of the optimal \\(p\\) can be determined by a number of model selection criteria (this is the focus of a later module). Exercise Using the tidyUSDA package, import price data for a commodity of your choice from 1990 – 2020. Following the forecasting techniques in this and the previous module: obtain the monthly series declared as a tsibble object with the appropriate index. present a time series plot of the data. comment on what patterns you observe from part 2. produce a forecast for the next 2 years using Holt’s Method Holt-Winter’s Method present the model summaries from the following model using a regression approach Trend Model Seasonal Model (using dummies) Trend and Seasonal Model present a single graph of the data against the fitted values of each of the three models from your results in 5. Which model appears to do the best job at predicting your price series? produce a forecast for the next 2 years using your preferred model in 6. "],["balance-sheet-forecasting.html", "Module 5 Balance Sheet Forecasting 5.1 Supply Forecasts 5.2 Utilization forecasts 5.3 Alternative Approaches 5.4 Forecast adjustments during the marketing year: Pace of Use (POU). 5.5 Food, Seed, and Industrial (FSI) 5.6 Grain Stocks and quarterly use dynamics.", " Module 5 Balance Sheet Forecasting So far, we have discussed forecasting of a single variable at a time. However, forecasting practices are often not singular or independent. A good example of it is forecasting supply and use categories within a balance sheet published in a WASDE report. While individual forecasting approaches may (need to) be applied, at the end of the day it is essential for the balance sheet to balance and individual forecasts to fit within a balance sheet structure and agreement. Furthermore, WASDE forecasts should be consistent with other reports, such as Grain Stocks, Export Sales and ethanol production. A balance sheet is structured as follows: \\[\\begin{align*} \\text{Total Supply} &amp;= \\text{Beginning Stocks} + \\text{Production} + \\text{Imports} \\\\ \\text{Total Use} &amp;= \\text{Domestic Use} + \\text{Exports} \\\\ \\text{Ending Stocks} &amp;= \\text{Total Supply} - \\text{Total Use}\\\\ \\end{align*}\\] Furthermore, WASDE forecasts should be consistent with other reports, such as Grain Stocks, Export Sales and ethanol production. In this module we will discuss forecasting approaches required to consolidate different variables within a forecasting system, such as share of total, and pace of use approaches. These approaches are particularly relevant for utilization forecasts as they are constrained by forecasted supply levels. 5.1 Supply Forecasts 5.1.1 Production Balance sheet forecasting typically starts on the supply side with forecasting yield, as we did in one of the previous modules. Once the yield forecast is produced, it becomes a foundation of a production forecast: \\[ \\text{Production} = \\widehat{\\text{yield}} \\times \\widehat{\\text{harvested acreage}}\\]. In order to get a forecast of the harvested acreage, planted acreage is multiplied by the average loss ratio over the recent period. The loss ratio is calculated as the ratio of harvested to planted acreage and describes the share of the planted acreage that is harvested. \\[\\begin{align*} \\text{Loss Ratio} &amp;= {\\text{Harvested Acreage}\\over \\text{Planted Acreage}}\\\\ \\implies \\text{Harvested Acreage} &amp;= \\text{Loss Ratio}\\times \\text{Planted Acreage} \\end{align*}\\] 5.1.2 Activity I: Forecasting Corn Production I. Download the planted and harvested data for CORN from Quick stats for 1986–2021, inclusive. Calculate the average loss ratio over the last 5 years. Calculate 2022 production estimate. Assume an estimate crop yield of 177 bushels/acre. In a single step, we will Pull the data, Keep only the annual values and renamed Value as harvest, Declare as a tsibble object, Store the variable also as harvest. ## Downloading Harvest Data for Corn (1986 -- 2021) harvest &lt;- tidyUSDA::getQuickstat( key = key, program = &quot;SURVEY&quot;, sector = &quot;CROPS&quot;, group = &quot;FIELD CROPS&quot;, commodity = &quot;CORN&quot;, category = &quot;AREA HARVESTED&quot;, data_item = &quot;CORN, GRAIN - ACRES HARVESTED&quot;, domain = &quot;TOTAL&quot;, geographic_level = &quot;NATIONAL&quot;, state = &quot;US TOTAL&quot;, year = as.character(1986:2021)) %&gt;% filter(reference_period_desc == &quot;YEAR&quot;) %&gt;% rename(harvest = Value) %&gt;% select(c(year, harvest)) %&gt;% as_tsibble(index = year) harvest ## # A tsibble: 36 x 2 [1Y] ## year harvest ## &lt;int&gt; &lt;dbl&gt; ## 1 1986 68907000 ## 2 1987 59505000 ## 3 1988 58250000 ## 4 1989 64783000 ## 5 1990 66952000 ## 6 1991 68822000 ## 7 1992 72077000 ## 8 1993 62933000 ## 9 1994 72514000 ## 10 1995 65210000 ## # ℹ 26 more rows Similarly, for the planted acreage, we will Pull the data, Keep only the annual values and renamed Value as planted, Declare as a tsibble object, Store the variable also as planted. ## Downloading Planted Acreage Data for Corn (1986 -- 2021) planted &lt;- tidyUSDA::getQuickstat( key = key, program = &quot;SURVEY&quot;, sector = &quot;CROPS&quot;, group = &quot;FIELD CROPS&quot;, commodity = &quot;CORN&quot;, category = &quot;AREA PLANTED&quot;, data_item = &quot;CORN - ACRES PLANTED&quot;, domain = &quot;TOTAL&quot;, geographic_level = &quot;NATIONAL&quot;, state = &quot;US TOTAL&quot;, year = as.character(1986:2021)) %&gt;% filter(reference_period_desc == &quot;YEAR&quot;) %&gt;% rename(planted = Value) %&gt;% select(c(year, planted)) %&gt;% as_tsibble(index = year) planted ## # A tsibble: 36 x 2 [1Y] ## year planted ## &lt;int&gt; &lt;dbl&gt; ## 1 1986 76580000 ## 2 1987 66200000 ## 3 1988 67717000 ## 4 1989 72322000 ## 5 1990 74166000 ## 6 1991 75957000 ## 7 1992 79311000 ## 8 1993 73239000 ## 9 1994 78921000 ## 10 1995 71479000 ## # ℹ 26 more rows After combining both data sets, we are able to compute the historical loss ratios. We can also compute the 5-year moving averages of the loss-ratio. This will help with the second portion of the activity. corn &lt;- left_join(harvest, planted, by = join_by(year)) %&gt;% mutate(loss.ratio = harvest/planted, `5-MA_loss` = slider::slide_dbl(loss.ratio, mean, .before =4, .after = 0, .complete = TRUE) ) corn ## # A tsibble: 36 x 5 [1Y] ## year harvest planted loss.ratio `5-MA_loss` ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1986 68907000 76580000 0.900 NA ## 2 1987 59505000 66200000 0.899 NA ## 3 1988 58250000 67717000 0.860 NA ## 4 1989 64783000 72322000 0.896 NA ## 5 1990 66952000 74166000 0.903 0.891 ## 6 1991 68822000 75957000 0.906 0.893 ## 7 1992 72077000 79311000 0.909 0.895 ## 8 1993 62933000 73239000 0.859 0.895 ## 9 1994 72514000 78921000 0.919 0.899 ## 10 1995 65210000 71479000 0.912 0.901 ## # ℹ 26 more rows Now to produce some quick plots: corn %&gt;% ggplot() + geom_line(aes(x = year, y = harvest/1e6, color = &quot;Harvest&quot;), size = 1.1) + geom_line(aes(x = year, y = planted/1e6, color = &quot;Planted&quot;), size = 1.1) + labs(title = &quot;Acres Planted &amp; Harvested&quot;, y = &quot;(million Acres)&quot;, x = NULL) + guides(colour = guide_legend(&quot;&quot;)) + theme_bw() Now for the loss ratio: corn %&gt;% ggplot() + geom_line(aes(x = year, y = loss.ratio, color = &quot;Loss Ratio&quot;), size = 1.1) + geom_line(aes(x = year, y = `5-MA_loss`, color = &quot;5-year Moving Average&quot;), size = 1.1) + labs(title = &quot;Annual Loss Ratio&quot;, y = NULL, x = NULL) + guides(colour = guide_legend(&quot;&quot;)) + theme_bw() We can now forecast the 2022 value of Production. At the time of writing, the planted acreage was 88,579,000. yield.22 &lt;- 177 planted.22 &lt;- 88579000 harvest.22 &lt;- last(corn$`5-MA_loss`) * planted.22 prod.22 &lt;- yield.22*harvest.22 prod.22 ## [1] 14302959311 5.1.3 Other Supply Components Once the production forecast is generated, it is added to beginning stocks and imports forecasts to result in total supply. Beginning stocks are equivalent to ending stocks from the previous marketing year. Imports are a relatively small category forecasted based on historical trends. The Feed Grains database maintained by the USDA ERS is a great source of historical data for WASDE forecasts. 5.1.4 Activity II Download the data from Feed Grains database into R. Our focus will be on the Corn Table (Table4) in Sheet #5 of the workbook. Using the marketing year (MY) values, plot the data relating to imports. What patterns do you observe in annual data? What would be your best estimate for 2022? Calculate total supply for 2022. Total supply becomes an upper bound for utilization forecasts. To reduce the risk of errors and additional steps, we can pull the .xlsx file directly into R from the ERS website. We will utilize the openxlsx package, so this would be a good time to install it if you haven’t previously. #Get the Source file hyperlink link &lt;- &quot;https://www.ers.usda.gov/webdocs/DataFiles/50048/Feed%20Grains%20Yearbook%20Tables-All%20Years.xlsx?v=3507.6&quot; ## The corn data is the 5th sheet of the file and the relevant data starts on row 4. grains.corn &lt;- openxlsx::read.xlsx(link, sheet = 5, startRow = 4) For our purpose, we will work with the marketing year (MY) data. We can therefore filter the rows to keep only those with the content MY Sept-Aug. Since we will lose the years, I will recreate that using the row_number command offset by 1974 (the year just before the first observation). Last, drop the value for 2022. grains.final &lt;- grains.corn %&gt;% filter(X2 == &quot;MY Sep-Aug&quot;) %&gt;% #rename the first column as year rename(year = X1) %&gt;% # Add proper years to each row mutate(year = row_number() + 1974) %&gt;% #drop the X2 column select(-c(X2)) %&gt;% #Drop years after 2021 filter(year &lt; 2022) grains.final %&gt;% head() ## year Beginning.stocks Production Imports Total.supply.2/ ## 1 1975 558.0 5840.757 1.497 6400.254 ## 2 1976 633.2 6289.169 2.431 6924.800 ## 3 1977 1135.6 6505.041 2.398 7643.039 ## 4 1978 1435.9 7267.927 1.152 8704.979 ## 5 1979 1709.5 7928.139 0.721 9638.360 ## 6 1980 2034.3 6639.396 0.848 8674.544 ## Food,.alcohol,.and.industrial.use Seed.use Feed.and.residual.use ## 1 500.7 20.1 3581.760 ## 2 522.1 20.1 3601.881 ## 3 561.5 19.5 3729.743 ## 4 588.5 19.5 4274.362 ## 5 619.5 20.0 4563.043 ## 6 639.0 20.2 4232.138 ## Total.domestic.use.2/ Exports Total.disappearance.2/ Ending.stocks ## 1 4102.560 1664.494 5767.054 633.2 ## 2 4144.081 1645.119 5789.200 1135.6 ## 3 4310.743 1896.396 6207.139 1435.9 ## 4 4882.362 2113.117 6995.479 1709.5 ## 5 5202.543 2401.517 7604.060 2034.3 ## 6 4891.338 2391.106 7282.444 1392.1 With all the data imported, we can turn our attention to the imports category. grains.final %&gt;% ggplot() + geom_line(aes(x = year, y = Imports), color = &quot;maroon&quot;, size = 1.1) + labs(y = &quot;million bushels&quot;, title = &quot;Supply - Corn Imports&quot;, x = NULL) + theme_bw() Corn imports have remained fairly low across the sample. There is a slight positive trend in the data. 2012 was an outlier with exports reaching almost 160 million bushels. Given the dynamics of this graph, our estimate for 2022, using expert judgement, might vary. A feasible estimate could be the average of the last 5-years. mean.imports &lt;- tail(grains.final$Imports, 5) %&gt;% mean() mean.imports ## [1] 30.8634 Another would be to use a naïve estimate. naive.imports &lt;- last(grains.final$Imports) naive.imports ## [1] 24.227 The Imports component forms such a small portion of the Total Supply category that we need not get too involved in its forecast. We are now ready to provide a forecast of Total Supply for 2022. Recall that the beginning stocks value for 2022 is 2021’s ending stocks. TS.22 &lt;- prod.22 + last(grains.final$Ending.stocks) + naive.imports TS.22 ## [1] 14302960712 5.2 Utilization forecasts 5.2.1 Top-down approach. General components Utilization categories typically include two components: domestic use and exports. One way to forecast utilization is to start with a forecast of total disappearance, which is then allocated to predicted shares of domestic use and exports. Alternatively, various utilization components are forecasted as proportions of total supply. We refer to this as a top-down approach. 5.2.2 Activity III Using the data from the Feed Grains database from earlier, plot the data for total supply, total disappearance, total domestic use and exports. Discuss patterns in the annual data. Next, we will plot each category as a percent of total supply. Again, discuss the patterns in the data. How would you produce an estimate for each category for 2022 based on expected share of total supply? grains.final %&gt;% ggplot() + geom_line(aes(x = year, y = `Total.supply.2/`, color = &quot;Total Supply&quot;), size = 1.1) + geom_line(aes(x = year, y = `Total.disappearance.2/`, color = &quot;Total Disappearance&quot;), size = 1.1) + geom_line(aes(x = year, y = `Total.domestic.use.2/`, color = &quot;Total Domestic Use&quot;), size = 1.1) + geom_line(aes(x = year, y = Exports, color = &quot;Exports&quot;), size = 1.1) + labs(title = &quot;Supply vs Use&quot;, y = &quot;million bushels&quot;, x = NULL) + guides(color = guide_legend(&quot;Component&quot;)) + theme_bw() + theme(legend.position = &quot;bottom&quot;) grains.final&lt;- grains.final %&gt;% ## Create the proportions ### Disappearance mutate(prop.disp = `Total.disappearance.2/`/(`Total.supply.2/`), ### Domestic use prop.dom = `Total.domestic.use.2/`/(`Total.supply.2/`), ### Exports prop.export = Exports/(`Total.supply.2/`) ) grains.final %&gt;% head() ## year Beginning.stocks Production Imports Total.supply.2/ ## 1 1975 558.0 5840.757 1.497 6400.254 ## 2 1976 633.2 6289.169 2.431 6924.800 ## 3 1977 1135.6 6505.041 2.398 7643.039 ## 4 1978 1435.9 7267.927 1.152 8704.979 ## 5 1979 1709.5 7928.139 0.721 9638.360 ## 6 1980 2034.3 6639.396 0.848 8674.544 ## Food,.alcohol,.and.industrial.use Seed.use Feed.and.residual.use ## 1 500.7 20.1 3581.760 ## 2 522.1 20.1 3601.881 ## 3 561.5 19.5 3729.743 ## 4 588.5 19.5 4274.362 ## 5 619.5 20.0 4563.043 ## 6 639.0 20.2 4232.138 ## Total.domestic.use.2/ Exports Total.disappearance.2/ Ending.stocks prop.disp ## 1 4102.560 1664.494 5767.054 633.2 0.9010664 ## 2 4144.081 1645.119 5789.200 1135.6 0.8360097 ## 3 4310.743 1896.396 6207.139 1435.9 0.8121297 ## 4 4882.362 2113.117 6995.479 1709.5 0.8036181 ## 5 5202.543 2401.517 7604.060 2034.3 0.7889371 ## 6 4891.338 2391.106 7282.444 1392.1 0.8395189 ## prop.dom prop.export ## 1 0.6409996 0.2600669 ## 2 0.5984405 0.2375692 ## 3 0.5640090 0.2481207 ## 4 0.5608700 0.2427481 ## 5 0.5397747 0.2491624 ## 6 0.5638726 0.2756463 On average, it appears that exports follow a constant trend-line with variation around the mean produced by years of surplus or scarcity. The drought year 2012, for example is clearly visible as an exceedingly low export year. We can now visualize the dynamics of the proportions over time. grains.final %&gt;% ggplot() + geom_line(aes(x = year, y = prop.disp, color = &quot;Total Disappearance&quot;), size = 1.1) + geom_line(aes(x = year, y = prop.dom, color = &quot;Total Domestic Use&quot;), size = 1.1) + geom_line(aes(x = year, y = prop.export, color = &quot;Exports&quot;), size = 1.1) + labs(title = &quot;Use as proportions of Total Supply&quot;, y = &quot;%&quot;, x = NULL) + guides(color = guide_legend(&quot;Components&quot;)) + theme_bw() + theme(legend.position = &quot;bottom&quot;) When exports are viewed as a proportion of production, we see a pronounced downward trend. This is due to the increasing share of production allocated to the Food, seed, and Industrial category. Exports is the most price sensitive category due to strong international competition. 5.2.3 Top-down approach. Specific components Activity IV Plot and examine the dynamics of the components of the Total Domestic Use category (FAI, Seed, Feed and residual). Compute and plot their respective ratios as a percentage of Total Supply. Produce a forecast of Total Use and Ending Stocks. grains.final %&gt;% ggplot() + geom_line(aes(x = year, y = `Food,.alcohol,.and.industrial.use`, color = &quot;Food, alcohol, and industrial use&quot;), size = 1.1) + geom_line(aes(x = year, y = Seed.use, color = &quot;Seed Use&quot;), size = 1.1) + geom_line(aes(x = year, y = Feed.and.residual.use, color = &quot;Feed and Residual Use&quot;), size = 1.1) + labs(title = &quot;Total Domestic Use&quot;, y = &quot;%&quot;, x = NULL) + guides(color = guide_legend(&quot;Components&quot;)) + theme_bw() + theme(legend.position = &quot;bottom&quot;) Computing the relative proportions: grains.final&lt;- grains.final %&gt;% ## Create the proportions ### FAI mutate(prop.fai = `Food,.alcohol,.and.industrial.use`/(`Total.supply.2/`), ### Seed Use prop.seed = Seed.use/(`Total.supply.2/`), ### Exports prop.feed = Feed.and.residual.use/(`Total.supply.2/`) ) grains.final %&gt;% head() ## year Beginning.stocks Production Imports Total.supply.2/ ## 1 1975 558.0 5840.757 1.497 6400.254 ## 2 1976 633.2 6289.169 2.431 6924.800 ## 3 1977 1135.6 6505.041 2.398 7643.039 ## 4 1978 1435.9 7267.927 1.152 8704.979 ## 5 1979 1709.5 7928.139 0.721 9638.360 ## 6 1980 2034.3 6639.396 0.848 8674.544 ## Food,.alcohol,.and.industrial.use Seed.use Feed.and.residual.use ## 1 500.7 20.1 3581.760 ## 2 522.1 20.1 3601.881 ## 3 561.5 19.5 3729.743 ## 4 588.5 19.5 4274.362 ## 5 619.5 20.0 4563.043 ## 6 639.0 20.2 4232.138 ## Total.domestic.use.2/ Exports Total.disappearance.2/ Ending.stocks prop.disp ## 1 4102.560 1664.494 5767.054 633.2 0.9010664 ## 2 4144.081 1645.119 5789.200 1135.6 0.8360097 ## 3 4310.743 1896.396 6207.139 1435.9 0.8121297 ## 4 4882.362 2113.117 6995.479 1709.5 0.8036181 ## 5 5202.543 2401.517 7604.060 2034.3 0.7889371 ## 6 4891.338 2391.106 7282.444 1392.1 0.8395189 ## prop.dom prop.export prop.fai prop.seed prop.feed ## 1 0.6409996 0.2600669 0.07823127 0.003140500 0.5596278 ## 2 0.5984405 0.2375692 0.07539568 0.002902611 0.5201422 ## 3 0.5640090 0.2481207 0.07346554 0.002551341 0.4879921 ## 4 0.5608700 0.2427481 0.06760499 0.002240097 0.4910250 ## 5 0.5397747 0.2491624 0.06427442 0.002075042 0.4734253 ## 6 0.5638726 0.2756463 0.07366381 0.002328653 0.4878802 Plotting the 3 components as a proportion of Total Use yields: grains.final %&gt;% ggplot() + geom_line(aes(x = year, y = prop.fai, color = &quot;Food, alcohol, and industrial use&quot;), size = 1.1) + geom_line(aes(x = year, y = prop.seed, color = &quot;Seed Use&quot;), size = 1.1) + geom_line(aes(x = year, y = prop.feed, color = &quot;Feed &amp; Residual Use&quot;), size = 1.1) + labs(y = &quot;%&quot;, title = &quot;Domestic Use as a proportion of Total Supply&quot;) + guides(color = guide_legend(&quot;Component&quot;)) + theme_bw() + theme(legend.pos = &quot;bottom&quot;) FAI: A dramatic increase in the Food, Alcohol and Industrial use is due to the dramatic increase in the production of ethanol starting around 2005/2006 and plateauing around 2010 when U.S. ethanol consumption roughly hit the ‘blend-wall’ where ethanol makes up 10% of the retail gasoline supply. Thus, gasoline consumption from EIA can be used to forecast or gauge the pace of ethanol consumption. This is the least price sensitive category as ethanol use is essentially mandated as part of gasoline use. Seeds: The series is flat, small, and very predictable. Feed and Residual: Feed and residual Feed and Residual category is the most difficult to forecast as we have the least amount of additional information regarding it. It should correlate roughly to livestock feeding units, but does not prove to be that effective in practice. Spare a thought: How would you produce an estimate for specific use category for 2022 based on expected share of production? Forecast of Total Use and Ending stocks Using this top-down method, we can compute the Total Use as a percentage of our forecasted total supply. The dynamics of the graphs above points to a number of potential forecasting approaches. Seed Use is such a small component and fairly flat that we could use a naive estimate. To get a bit of the variation into our estimates, we will use the 5 year MA for the FAI and Feed categories. The proportion of exports has been declining over time so we could model that with a “dampening” factor. Of course, a 5-year MA could work here. # Forecast FAI fai.22 &lt;- tail(grains.final$prop.fai,5) %&gt;% mean() # Forecast Feed use feed.22 &lt;- tail(grains.final$prop.feed,5) %&gt;% mean() # Forecast seed use seed.22 &lt;- last(grains.final$prop.seed) export.22 &lt;- tail(grains.final$prop.export,5) %&gt;% mean() ## Forecast of use pop.use &lt;- fai.22 + feed.22+ seed.22 + export.22 pop.use ## [1] 0.8913873 We forecast Total Use to be 89% of Total Supply. Therefore, we estimate Total use as: TotalUse.22 &lt;- TS.22*pop.use TotalUse.22 ## [1] 12749477938 Ending stock now becomes a residual category: endingStocks.22 &lt;- TS.22 - TotalUse.22 endingStocks.22 ## [1] 1553482774 Final Comments: The Top-down approach is effective because it is relatively easy to ensure that proportions of total use allocated to each category do not add up to more than 100%. 5.3 Alternative Approaches Bottom-up approach This approach would start with producing forecasts for specific components based on their growth rates and other parameters (e.g. percentage of expected gasoline use) or models and then reconciling them to satisfy supply constraints. For example, one could estimate ending stocks based on relationship between prices and ending stocks and calculate disappearance as the difference between total supply and ending stocks. Similar–year approach This is the least technical approach but history tends to repeat itself. Sometimes a lot can be learned from observing how markets reacted to similar conditions in the past. 5.4 Forecast adjustments during the marketing year: Pace of Use (POU). Methods described above are best suited in the beginning of the forecasting cycle when little or no information about current marketing year use is available. However, as we move through the marketing year and achieve access to this information, your initial estimates should be cross checked with what we learn about the pace of use during the year. Utilization categories differ substantially with regard to the amount and timeliness of the available information. Export sales are updated in the most timely manner (weekly). 5.4.1 Exports Two USDA agencies are involved in providing estimates of export sales. The USDA Foreign Agricultural Service (https://www.fas.usda.gov/) and the Federal Grain Inspection Services (https://fgisonline.ams.usda.gov/). The FAS maintains the Export Sales Query System (https://apps.fas.usda.gov/esrquery/), which reports weekly export quantities and daily reports of large export sales. The pace of use method will allow us to compare the pace of export sales during the current marketing year 2022/23 to the pace of export sales in the previous three marketing years. Moreover, we can make inferences about whether this marketing year has gotten off to a good start in export sales. 5.4.2 Activity V Using the Export Sales Query System, pull data on the Weekly Corn exports for the MY 2019/20 – 7/14/2022. The important parameters are as follows: For the sake of convenience, we have stored the data to a Github repository. Also, the file format has been changed to an xlsx document to keep the number of required packages and lines of codes to a minimum. Our column of interest is the Accumulated Exports (column 5) Using the historical values of the WASDE reports for each marketing year, compute the Pace of use across the weeks of each MY. The historical WASDE Export Values (in million bushels) are as follows: MY Value 2019/20 1777 2020/21 2747 2021/22 2472 These values should also correspond to the last 3 elements of the Export column of our grains report dataset (grains.final) from earlier. grains.final$Exports %&gt;% tail(3) ## [1] 1778.476 2746.937 2472.389 We will be required to convert from million bushels to metric tons. We will use a conversion factor of 1 bushel = .025401 metric ton. Since the actual data begins on Row #8 we will need to include that. corn.exports &lt;- openxlsx::read.xlsx( &quot;data/ExportSales_Corn.xlsx&quot;, startRow =8, detectDates = TRUE) corn.exports %&gt;% head() ## Commodity Date X3 Exports Exports Sales New.Sales Sales ## 1 Corn 2019-09-05 ENDING MY 277960 49202091 734420 74981 1625 ## 2 Corn 2019-09-05 STARTING MY 412243 412243 6778106 1317286 498090 ## 3 Corn 2019-09-12 &lt;NA&gt; 457306 869549 7785366 1477857 1464566 ## 4 Corn 2019-09-19 &lt;NA&gt; 278922 1148471 8000410 514405 493966 ## 5 Corn 2019-09-26 &lt;NA&gt; 458330 1606801 8104696 615215 562616 ## 6 Corn 2019-10-03 &lt;NA&gt; 474396 2081197 7914756 319226 284456 ## Commitment Sales Sales Unit.Desc ## 1 49936511 6778106 498090 Metric Tons ## 2 7190349 60000 0 Metric Tons ## 3 8654915 124914 64914 Metric Tons ## 4 9148881 124914 0 Metric Tons ## 5 9711497 127441 2527 Metric Tons ## 6 9995953 127441 0 Metric Tons There are a few additional edits that we need to perform. Drop all columns besides the Date, X3, and Accumulated Exports. The full name might be missing given that we started importing from Row 8. Drop all rows in X3, with “Ending MY” arguments. You will note that those dates have 2 observations. Drop X3. Create a week of the MY indicator. For simplicity, we can replicate the week numbers 1:52 out to the length of the full data set. final.exports &lt;- corn.exports[,c(2,3,5)] %&gt;% filter(X3 == &quot;STARTING MY&quot; | is.na(X3) ) %&gt;% mutate(week = rep_len(1:52,length(Date))) %&gt;% select(-c(X3)) final.exports %&gt;% head() ## Date Exports week ## 1 2019-09-05 412243 1 ## 2 2019-09-12 869549 2 ## 3 2019-09-19 1148471 3 ## 4 2019-09-26 1606801 4 ## 5 2019-10-03 2081197 5 ## 6 2019-10-10 2637782 6 Computing the POU and creating a MY indicator to make our graphs easier. conversion.factor &lt;- 25401 pou &lt;- final.exports %&gt;% mutate( wasde.exports = rep_len(rep(c(1777,2753,2450), each = 52), length.out = length(Date)), ## Create a column to capture the MYs MY = rep_len(rep(c(&quot;2019/20&quot;,&quot;2020/21&quot;,&quot;2021/22&quot;), each = 52), length(Date)), WASDE = wasde.exports*conversion.factor, POU = (Exports/WASDE)*100 ) pou %&gt;% head() ## Date Exports week wasde.exports MY WASDE POU ## 1 2019-09-05 412243 1 1777 2019/20 45137577 0.9133033 ## 2 2019-09-12 869549 2 1777 2019/20 45137577 1.9264415 ## 3 2019-09-19 1148471 3 1777 2019/20 45137577 2.5443789 ## 4 2019-09-26 1606801 4 1777 2019/20 45137577 3.5597857 ## 5 2019-10-03 2081197 5 1777 2019/20 45137577 4.6107858 ## 6 2019-10-10 2637782 6 1777 2019/20 45137577 5.8438715 Last, let us visualize the Pace of Use so far this year, relative to the past 3 marketing years. pou %&gt;% ggplot() + geom_line(aes(x = week, y = POU, group = MY, color = MY, linetype = MY), size = 1) + labs(title = &quot;Pace of Use&quot;, subtitle = &quot;By marketing year&quot;, y = &quot;% of MY&#39;s Total&quot;, x = &quot;Week&quot;) + theme_bw() We can observe that the Pace of Use thus far in 2021/22 is largely consistent with that of the previous MY (2020/21) and above MY 2019/20. 5.5 Food, Seed, and Industrial (FSI) Ethanol production is the primary user of corn in the Food, Seed, and Industrial Category. Data on monthly fuel ethanol production can be found at EIA.GOV Ethanol production and consumption increased rapidly after 2005, when the Energy Policy Act of 2005 and later the Energy Security and Independence Act of 2007 created the Renewable Fuels Standard (RFS). The RFS mandated quantities of ethanol that blenders of gasoline are required to blend into the retail gasoline supply. These annual mandates are revised every year, but they were designed to steadily increase year after year until 2015 when the mandate reached 15 billion gallons per year. This figure came about because gasoline consumption in the United States was forecast to reach 15 billion gallons per year by 2015. So the RFS mandates were designed to reach the point where the entire retail gasoline supply would include 10% ethanol. Incidentally, 300,000,000 barrels corresponds to 15 billion gallons (300,000,000*50gallons/barrel = 15,000,000,000 gallons), which is considered the “blend wall”. Going forward, without significant growth in the consumption of gasoline in the United States, this corn use category is likely to remain flat for the foreseeable future. Even so, ethanol blenders sometimes experience an ethanol-to-gasoline price ratio that is favorable to blending ethanol even above the levels of the RFS mandate. So conducting a pace-of-use analysis for this corn use category makes sense as well. Examining the current marketing year’s production of ethanol gives some indication of whether ethanol production is likely to exceed the 15 billion gallon per year mandated level. Starting in February 2015, direct estimates of the use of corn for ethanol and co-product production became available in the monthly Grain Crushings and Co-Product Production report. For more details see (https://farmdocdaily.illinois.edu/2016/07/revisiting-usda-corn-and-soybean-grain-stocks.html) 5.6 Grain Stocks and quarterly use dynamics. Feed Grains database contains quarterly data that can be used to gauge quarterly use dynamics. It is important to recognize equations that guide these data. Balance sheet always has to balance. Initial MY and Q1 supply is determined by beginning stocks, production and Q1 imports. Grain stocks reports provide information on the amount of corn (and other commodities) in storage for the following reference dates: September 1, December 1, March 1, and June 1. The September survey asks for separate estimates for old crop and new crop stocks. This data informs estimates for beginning stocks and endings stocks in Q1. The difference between total supply and ending stocks is total disappearance. Total disappearance consists of exports, FSI and Feed and residual use. We likely have the most updated information about exports, as shown in Activity 5, so that would be the category that is easiest to update. FAI use is the next category. It is fairly stable over time with additional information available from EIA, even though it becomes available with a lag. What is left after exports and FSI are estimated, is allocated to Feed and residual use, the category for which we have the least amount of information as there is no official measure or method to track corn disappearance into animal feeds. Analysts rely on the historical pattern of quarterly feed and residual use and changes in livestock numbers and availability of other grains for feeding in order to form estimates of use during the quarter. The historical pattern includes the well-known tendency of feed and residual use in corn to vary more with the size of the corn crop than is expected based purely on price changes. This leads to a positive correlation between feed and residual use and crop size that is “large.” Moving from Q1 to Q2 is also governed by equations. Q1 ending stocks are Q2 beginning stocks. Q2 beginning stocks and imports result in total supply for Q2. The difference between total supply and Q2 endings stocks is total disappearance. We repeat the process described for Q1 to allocate total disappearance to its components. "],["stocks-use.html", "Module 6 Forecasting Prices Using Stocks-to-Use Ratios 6.1 Stocks-to-Use Based Forecasting: A Replication 6.2 Optional Materials", " Module 6 Forecasting Prices Using Stocks-to-Use Ratios In the previous module we discussed forecasting various balance sheet components relating to either supply or utilization (consumption). Therefore, a commodity forecasting balance sheet reflects the current information about fundamental forces that drive market prices. This fundamental supply and demand information is connected to market prices through the ending stocks variable. This variable is not forecasted, but rather calculated as the difference between total supply and total use in the balance sheet. As a residual between supply and use, ending stocks represent a degree of scarcity (or plenitude) of the commodity in the market. As a result of this relative scarcity, low ending stocks are typically associated with high prices (and vice versa). Hence, the relationship between ending stocks and price is often used to forecast prices. We will start by introducing price forecasting models developed by Irwin and Good and described in this article. Before we formally examine the relationship between ending stocks and prices, it is customary to “normalize” ending stocks by the level of use through calculating a stocks-to-use ratio. The figure below shows changes in the average price of corn received as well as the stocks-to-use of corn over time. Corn Price and Stock/Use Pronounced stocks-to-use spikes occurred in the 1982/1983 and 1985/1986, 1986/1987, 1987/1988 marketing years. Those exceptionally high stocks relative to use was a result of government commodity programs designed to keep prices from falling too far. Specifically, the stocks were help primarily in the Farmer-Owned-Reserve or by the Commodity Credit Corporation (Westcott and Hoffman 1999). Both programs were designed to keep bushels off the market and thus buoying prices. During periods of prolonged excesses, however, it becomes very costly for the government to procure and store large quantities of the commodity and it has a continuing depressing effect on market prices because the market knows the government holds large stockpiles. Farm legislation (‘The Farm Bill’ is re-negotiated every four years by congress) has trended toward more market-oriented approaches to supporting agriculture, and one can observe a marked decline in stocks-to-use over time. Aside from the wild swings in the 1980’s, the series still seem to show a negative relationship between stocks-to-use and prices, as one would expect. Figure 1 from the article shows these two series as a scatter-plot with stocks-to-use on the x-axis and price on the y-axis. Figure 1: Reciprocal Regression Model Fit Good and Irwin argue that the relationship should be viewed in the context of two different eras. The first era spans from 1990-91 through 2005-06 and consists of the lower and more horizontal cluster of points in Figure 1. The second era spans from 2007-08 through 2014-15 and it contains the upper and more steeply sloped cluster of points in Figure 1. Note that 2006-07 is treated as a transition year is this division of eras. The two eras represented in Figure 1 are mainly differentiated by the substantial increase in ethanol demand for corn that began in 2007-08. That is, the outward shift in the demand curve resulted in higher prices, for a given level of supply, than was the case in the period prior to 2007-08. While the corn supply curve likely did not shift at first, there was undoubtedly movement along the supply curve as higher prices resulted in expanded corn acreage. The resulting large outward shift in the demand curve and movement along a relatively inelastic (price insensitive) supply curve meant that a stocks to-use ratio of a given magnitude was associated with a higher price in the latter era than in the former era. Next, the authors estimate the relationship between the average marketing year price and ending stock-to-use ratio for the two different eras over 1990-91 through 2014-15. A reciprocal regression specification is used, so that: \\(\\text{Corn Price} = a + \\frac{b}{\\text{Stocks/Use Ratio}}\\). This specification is simple and imposes a curvilinear relationship between price and the stocks-to-use ratio. That is, the curve becomes steeper and steeper as the stocks-to-use ratio declines, and vice versa. Separating the observations into two eras results in a good “fit” between the stocks-to-use ratio and the average marketing year farm price. The fit is particularly good in the latter period, with the stocks-to-use ratio explaining 86 percent of the annual variation in the marketing year average price from 2007-08 through 2014-15. As expected, the estimated regression line is much steeper for the second era compared to the first. While this model of the relationship between the stocks-to-use ratio and price appeared to provide a satisfactory level of explanation of the marketing year average farm price of corn, the ratio clearly did not satisfactorily explain the average farm price of soybeans. In fact, the authors concluded that the projected soybean stocks-to-use ratio was not useful in projecting the marketing year U.S. average price of soybeans. These potential problems motivated the search for an alternative model that would better explain the relationship between stocks and price for corn and soybeans. In an alternative specification, the authors estimate a base relationship for 1990-91 through 2005-2006, skip 2006-07 as a transition year, and then estimate relationships after 2005-06 that are exactly parallel to the base period model. Thus, the model has a base specification described in the equation above, excludes 2007-2007, and includes dummy variables for groups of years reflecting different strengths of demand. The first group includes 2009-10, 2014-15, and 2015-16 and represents “weak” demand after 2005-06. The second group represents the first level of “moderate” demand and includes 2007-08, 2008-09, and 2013-14. The third group contains only one year, 2010-11, and it represents the second level of “moderate” demand. The fourth and final group includes 2011-12 and 2012-13 and it represents “strong” demand. Figure 3: New Reciprocal Model A useful way to benchmark the strength of demand in the different groups is by comparing the intercepts, which estimate minimum (season-average farm) prices. From lowest to highest, the estimated intercepts are $2.96, $3.50, $4.20, and $5.44, which means that at any given stocks-to-use ratio the price of corn is $2.48 bushel higher under the strong demand relationship compared to weak demand. The \\(R^2\\) for the alternative model in Figure 3 is 0.99, but this is due to the inclusion of the dummy variables for the different groups of years. It is more important to note that all of the coefficients in the model are highly statistically significant. Next, we will demonstrate how to replicate this analysis using R and use it to generate a price forecast for the current marketing year. 6.1 Stocks-to-Use Based Forecasting: A Replication 6.1.1 Download our data for corn We can again use the openxlsx package to read in the corn data. Our focus is on the worksheet called Annual Data and we need to start from row 10. # pull the data from data folder dat &lt;- openxlsx::read.xlsx(&quot;data/CornSD.xlsx&quot;, sheet = &quot;Annual Data&quot;, startRow = 10, cols = 1:25) # Keep only the first Year column # Keep only rows 1:93 (the actual Years) dat &lt;- dat[1:93,-c(2:3)] dat %&gt;% head() ## Year Planted.Acres Harvested.Acres Actual.Yield Production Stocks Imports ## 1 1929 99130 97805 25.7 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 1930 103915 101465 20.5 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 3 1931 109364 106866 24.1 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 4 1932 113024 110577 26.5 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 5 1933 109830 105918 22.6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 6 1934 100563 92193 15.7 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## Total.Supply Seed Food,.Alcohol.&amp;.Industrial Corn.Used.for.Ethanol ## 1 &lt;NA&gt; &lt;NA&gt; NA NA ## 2 &lt;NA&gt; &lt;NA&gt; NA NA ## 3 &lt;NA&gt; &lt;NA&gt; NA NA ## 4 &lt;NA&gt; &lt;NA&gt; NA NA ## 5 &lt;NA&gt; &lt;NA&gt; NA NA ## 6 &lt;NA&gt; &lt;NA&gt; NA NA ## Feed.&amp;.Residual.Usage All.Dom..Use Exports Total.Usage Ending.Stocks Free ## 1 NA NA NA NA NA NA ## 2 NA NA NA NA NA NA ## 3 NA NA NA NA NA NA ## 4 NA NA NA NA NA NA ## 5 NA NA NA NA NA NA ## 6 NA NA NA NA NA NA ## Reserve CCC Loan Stock/Use.(%) Corn.Avg.Farm.Price ## 1 NA NA NA &lt;NA&gt; 0.79900000000000004 ## 2 NA NA NA &lt;NA&gt; 0.59799999999999998 ## 3 NA NA NA &lt;NA&gt; 0.32100000000000001 ## 4 NA NA NA &lt;NA&gt; 0.316 ## 5 NA NA NA &lt;NA&gt; 0.52 ## 6 NA NA NA &lt;NA&gt; 0.81499999999999995 6.1.2 Clean Data We need to create a data set using data starting in 1990 in order to replicate analysis in Irwin and Good (2016) study. Our focus in on Stock/Use (%) column and Corn Avg Farm Price column. Need to make sure the data is in numeric format. Use these data to calculate a new variable called “ratio”, defined as a ratio of 1 over stocks-to-use percentage (times 100). Select the data we will need for our analysis, consisting of year, su, price, and ratio. su.data &lt;- dat %&gt;% as_tsibble(index = Year) %&gt;% # Keep only years after 1989 filter_index(1990~.) %&gt;% # Convert stocks-to-use to numbers mutate(su = as.numeric(`Stock/Use.(%)`), # Convert sprice to numbers price = as.numeric(Corn.Avg.Farm.Price), ratio = 1/(su*100)) %&gt;% select(Year, su, price, ratio) su.data %&gt;% head() ## # A tsibble: 6 x 4 [1Y] ## Year su price ratio ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1990 0.196 2.28 0.0511 ## 2 1991 0.139 2.37 0.0720 ## 3 1992 0.249 2.07 0.0402 ## 4 1993 0.112 2.5 0.0896 ## 5 1994 0.166 2.26 0.0603 ## 6 1995 0.0500 3.24 0.200 To replicate analysis shown in Figure 1 we need to estimate regressions for 1990-2005 and 2007-2015 separately. 6.1.3 Sub Period 1: 1990-2005 reg1 &lt;- su.data %&gt;% filter_index(.~2005) %&gt;% model(TSLM(price ~ ratio)) reg1 %&gt;% report() ## Series: price ## Model: TSLM ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.27933 -0.11909 -0.02277 0.12216 0.24056 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.6351 0.0975 16.770 1.15e-10 *** ## ratio 8.3821 1.1623 7.212 4.48e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1733 on 14 degrees of freedom ## Multiple R-squared: 0.7879, Adjusted R-squared: 0.7727 ## F-statistic: 52.01 on 1 and 14 DF, p-value: 4.4839e-06 6.1.4 Sub Period 2: 2007 - 2015/16 reg2 &lt;- su.data %&gt;% filter_index(2007~2015) %&gt;% model(TSLM(price ~ ratio)) reg2 %&gt;% report() ## Series: price ## Model: TSLM ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.7595 -0.2489 -0.1927 0.4843 0.5215 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.3554 0.6841 0.520 0.619406 ## ratio 44.5375 6.8862 6.468 0.000344 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4857 on 7 degrees of freedom ## Multiple R-squared: 0.8566, Adjusted R-squared: 0.8362 ## F-statistic: 41.83 on 1 and 7 DF, p-value: 0.00034447 6.1.5 Producing Figure 1 Our goal is to build a scatter plot showing prices against stock/use ratios replicating Figure 1. To replicate the fitted/regression lines on the graph, we will plug potential Ending Stocks/Use values (along the x-axis) into our respective estimated regression equations to generate fitted values. x &lt;- seq(5,27, by = 3) #Extracting regression coefficients price1 &lt;- coef(reg1)[[1,3]] + (coef(reg1)[[2,3]])*(1/x) x2 &lt;- seq(7.5,15, by = 2) price2 &lt;- coef(reg2)[[1,3]] + (coef(reg2)[[2,3]])*(1/x2) reg_lines &lt;- data.frame(x = x, reg1 = price1) reg_lines2 &lt;- data.frame(x = x2, reg2 = price2) Now, we are ready to produce our plots. su.data %&gt;% filter_index(.~2015) %&gt;% ggplot(aes(x = (su*100), y = price)) + geom_point(color = &quot;blue&quot;, pch = &quot;diamond&quot;, size = 2.5) + geom_line(data = reg_lines, aes(x = x, y = price1, color = &quot;1990/91 - 2005/06&quot;), lwd = 1.25) + geom_line(data = reg_lines2, aes(x = x2, y = price2, color = &quot;2007/08 - 2015/16&quot;), lwd = 1.25) + guides(color = guide_legend(&quot;Period&quot;)) + labs(title = &quot;Figure 1 - Replication&quot;, y = &quot;Price ($/bu)&quot;, x = &quot;Ending Stocks/Use (%)&quot; ) + theme_bw() 6.1.6 Market Condition Dummies To go from Figure 1 to Figure 3, we need to create market conditions dummy variables, as described in the last paragraph on page 4 of Irwin and Good’s paper. First, we create sub-samples for each market regime. Second we drop 2006, as it is considered a “transitional” year and is excluded from analysis. We also need to limit the sample not to include data post 2015. weak &lt;- c(2009, 2014:2015) mod2 &lt;- c(2007:2008, 2013) mod1 &lt;- 2010 strong &lt;- 2011:2012 #Drop 2006, and all years after 2015. subdata &lt;- su.data %&gt;% filter(Year %in% c(1990:2005, 2007:2015)) subdata %&gt;% head() ## # A tsibble: 6 x 4 [1Y] ## Year su price ratio ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1990 0.196 2.28 0.0511 ## 2 1991 0.139 2.37 0.0720 ## 3 1992 0.249 2.07 0.0402 ## 4 1993 0.112 2.5 0.0896 ## 5 1994 0.166 2.26 0.0603 ## 6 1995 0.0500 3.24 0.200 Once we formatted the data, we can create our desired new variables. subdata &lt;- subdata %&gt;% mutate(weak = ifelse(Year %in% weak, 1,0), mod2 = ifelse(Year %in% mod2, 1,0), mod1 = ifelse(Year %in% mod1, 1,0), strong = ifelse(Year %in% strong, 1,0)) subdata ## # A tsibble: 25 x 8 [1Y] ## Year su price ratio weak mod2 mod1 strong ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1990 0.196 2.28 0.0511 0 0 0 0 ## 2 1991 0.139 2.37 0.0720 0 0 0 0 ## 3 1992 0.249 2.07 0.0402 0 0 0 0 ## 4 1993 0.112 2.5 0.0896 0 0 0 0 ## 5 1994 0.166 2.26 0.0603 0 0 0 0 ## 6 1995 0.0500 3.24 0.200 0 0 0 0 ## 7 1996 0.100 2.71 0.0995 0 0 0 0 ## 8 1997 0.149 2.43 0.0672 0 0 0 0 ## 9 1998 0.192 1.94 0.0520 0 0 0 0 ## 10 1999 0.181 1.82 0.0554 0 0 0 0 ## # ℹ 15 more rows Now that the data is ready, we can combine it to show relationships illustrated in Figure 3. reg.all &lt;- subdata %&gt;% model( TSLM(price ~ ratio + weak + mod2 + mod1 + strong)) reg.all %&gt;% report() ## Series: price ## Model: TSLM ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.2994 -0.1125 0.0000 0.1118 0.2994 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.62417 0.09947 16.33 1.23e-12 *** ## ratio 8.52790 1.18120 7.22 7.43e-07 *** ## weak 1.32899 0.11305 11.76 3.66e-10 *** ## mod2 1.89273 0.11366 16.65 8.64e-13 *** ## mod1 2.56885 0.19122 13.43 3.77e-11 *** ## strong 3.81502 0.14990 25.45 3.83e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1796 on 19 degrees of freedom ## Multiple R-squared: 0.9868, Adjusted R-squared: 0.9833 ## F-statistic: 283.9 on 5 and 19 DF, p-value: &lt; 2.22e-16 6.1.6.1 Adding the Regression lines to Figure 3 Using the same construct as above, we can generate the fitted values (regression lines) for the 5 demand curves. x.c = seq(5,25, by = 0.5) base = coef(reg.all)[[2,3]]*(1/x.c) + coef(reg.all)[[1,3]] weak = coef(reg.all)[[2,3]]*(1/x.c) + (coef(reg.all)[[1,3]] + coef(reg.all)[[3,3]]) mod2 = coef(reg.all)[[2,3]]*(1/x.c) + (coef(reg.all)[[1,3]] + coef(reg.all)[[4,3]]) mod1 = coef(reg.all)[[2,3]]*(1/x.c) + (coef(reg.all)[[1,3]] + coef(reg.all)[[5,3]]) strong = coef(reg.all)[[2,3]]*(1/x.c) + (coef(reg.all)[[1,3]] + coef(reg.all)[[6,3]]) demand &lt;- data.frame(x= x.c, base=base, weak = weak, mod2 = mod2, mod1 = mod1, strong = strong) Again, we can plot the results as follows: demand %&gt;% pivot_longer(!x, names_to = &quot;Demand&quot;, values_to = &quot;Price&quot;) %&gt;% ggplot() + geom_line(aes(x = x, y = Price, group = Demand), colour = &quot;hotpink&quot;, lwd = 2) + geom_point(aes(x = su*100, y = price), data = subdata, size = 2.5, color = &quot;darkblue&quot;, pch = &quot;diamond&quot;) + labs(title = &quot;Figure 3 - Replication&quot;, y = &quot;Price ($/bu)&quot;, x = &quot;Ending Stocks/Use (%)&quot; ) + theme_bw() 6.1.7 Forecast Price for 2021 Our next goal is to use the regression estimates from this method and this sample to generate corn price forecasts for 2021. Why would we use the original sample estimates for these regressions and not simply extend our data through to 2020? Answer: This regression method will require that we make assumptions about the market conditions between 2016 and 2020. To avoid this, we will use the coefficient estimates from the regression model using data from 1990 – 2015, and excluding 2006. We start by creating names for our forecasts. Our forecast will be based on the new value of Stocks/Use ratio from the most recent balance sheet (2021 forecasts) and will generate and estimate for each potential market regime (scenario). future_scenarios &lt;- scenarios( weak = new_data(subdata,1) %&gt;% mutate(ratio = 0.08477816, weak = 1, mod2 = 0, mod1 = 0, strong = 0), moderate2 = new_data(subdata,1) %&gt;% mutate(ratio = 0.08477816, weak = 0, mod2 = 1, mod1 = 0, strong = 0), moderate1 = new_data(subdata,1) %&gt;% mutate(ratio = 0.08477816, weak = 0, mod2 = 0, mod1 = 1, strong = 0), strong = new_data(subdata,1) %&gt;% mutate(ratio = 0.08477816, weak = 0, mod2 = 0, mod1 = 0, strong = 1), names_to = &quot;Scenario&quot; ) forecast21 &lt;- reg.all %&gt;% forecast(new_data = future_scenarios) subdata %&gt;% autoplot(price) + autolayer(forecast21, level = NULL) + labs(title = &quot;Scenario Forecasts for Prices in 2021&quot;) + theme_bw() Alternative Approach Alternatively we can extend our regression estimates through 2020 This will require that we make assumptions about the market conditions between 2016 and 2020. 2016-2020 were characterized by low prices which could have been caused by weak market conditions and associated with trade war with China in 2019. Thus, we add these years to the “weak” dummy variable. To revise our analysis we need to go back and revise our definitions of market conditions and extend the time period included for analysis. weak &lt;- c(2009, 2014:2020) mod2 &lt;- c(2007:2008, 2013) mod1 &lt;- 2010 strong &lt;- 2011:2012 #Drop 2006 subdata &lt;- su.data %&gt;% filter(Year %in% c(1990:2005,2007:2020)) subdata &lt;- subdata %&gt;% mutate(weak.d = ifelse(Year %in% weak, 1,0), mod2.d = ifelse(Year %in% mod2, 1,0), mod1.d = ifelse(Year %in% mod1, 1,0), strong.d = ifelse(Year %in% strong, 1,0)) subdata ## # A tsibble: 30 x 8 [1Y] ## Year su price ratio weak.d mod2.d mod1.d strong.d ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1990 0.196 2.28 0.0511 0 0 0 0 ## 2 1991 0.139 2.37 0.0720 0 0 0 0 ## 3 1992 0.249 2.07 0.0402 0 0 0 0 ## 4 1993 0.112 2.5 0.0896 0 0 0 0 ## 5 1994 0.166 2.26 0.0603 0 0 0 0 ## 6 1995 0.0500 3.24 0.200 0 0 0 0 ## 7 1996 0.100 2.71 0.0995 0 0 0 0 ## 8 1997 0.149 2.43 0.0672 0 0 0 0 ## 9 1998 0.192 1.94 0.0520 0 0 0 0 ## 10 1999 0.181 1.82 0.0554 0 0 0 0 ## # ℹ 20 more rows The rest of the code should work without any changes. These forecasts are based on a full dataset from 1990 through 2020, excluding 2006. 6.2 Optional Materials Other illustrations of forecasting prices using stocks-to-use and other variables include: Forecasting Cotton Prices Forecasting World Cotton Price Modelling Soybean Prices in a Changing Policy Price Determination for Corn and Wheat "],["accuracy.html", "Module 7 Accuracy and Forecast Evaluations 7.1 Corn Data (Revisited) 7.2 Exploring the Forecasting models In-sample 7.3 Out-of-sample forecasts 7.4 Model Evaluation", " Module 7 Accuracy and Forecast Evaluations In the preceding Modules, we focused much of our attention on exploring various forecasting models. We quickly saw that some models did a better job of fitting and predicting our data than others. To this point, our determination of the “best” models was entirely based on eyeballing the “goodness of fit” of the actual vs the forecasted data series. In this module, we shift our focus to formally assessing our model’s forecasting performances. We will return to the Annual Corn Price series from earlier and statistically determine the most accurate forecasting model, both in- and out-of-sample. 7.1 Corn Data (Revisited) As we did in Module 6, we can again read in the dataset with the Ending Stocks/Use. We leave it as practice for interested reader to duplicate the codes and manipulations in Sections 6.1.1 and 6.1.2. For the purpose of the exercise, we will drop the observations for 2021. To refamiliarize ourselves with the data: su.data2 &lt;- su.data %&gt;% filter_index(.~2020) su.data2 %&gt;% autoplot(price, color = &quot;blue&quot;, size = 1.15) + geom_point() + labs(title = &quot;Time Plot of Corn Prices&quot;, y = &quot;$/bu&quot;, x = &quot;Year&quot;) + theme_bw() From the plot, the price series appears to be increasing over time. From this pattern, a trend model could conceivably be a viable candidate for our forecasting. 7.2 Exploring the Forecasting models In-sample To begin, we will subset our data into a training and test period. The test period will serve as our data validation window. That is, we will use it to understand how well our model performs “out of sample”. We will use the last 5 years of data as the test period. # Create the training set train &lt;- su.data2 %&gt;% filter_index(.~2015) train %&gt;% head() ## # A tsibble: 6 x 4 [1Y] ## Year su price ratio ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1990 0.196 2.28 0.0511 ## 2 1991 0.139 2.37 0.0720 ## 3 1992 0.249 2.07 0.0402 ## 4 1993 0.112 2.5 0.0896 ## 5 1994 0.166 2.26 0.0603 ## 6 1995 0.0500 3.24 0.200 # Reserve the last 5 years for the test set test &lt;- su.data2 %&gt;% filter_index(2016~.) test %&gt;% head() ## # A tsibble: 5 x 4 [1Y] ## Year su price ratio ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2016 0.157 3.36 0.0639 ## 2 2017 0.145 3.36 0.0691 ## 3 2018 0.155 3.61 0.0643 ## 4 2019 0.137 3.56 0.0728 ## 5 2020 0.0744 4.4 0.134 7.2.1 Method 1: Linear Trend Let us first explore the forecasting method using a simple trend. Recall that we can achieve this using a time series linear model (OLS) and the TSLM function. mod1.trend &lt;- train %&gt;% model(trend = TSLM(price ~ trend())) mod1.trend %&gt;% report() ## Series: price ## Model: TSLM ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.42357 -0.79770 0.02143 0.53242 2.62181 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.49302 0.41302 3.615 0.001385 ** ## trend() 0.12066 0.02674 4.512 0.000144 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.023 on 24 degrees of freedom ## Multiple R-squared: 0.4589, Adjusted R-squared: 0.4364 ## F-statistic: 20.36 on 1 and 24 DF, p-value: 0.00014377 From the regression results, the linear trend appears to be statistically significant in explaining the observed prices. At this point, it would also prove useful to produce the plot of the fitted and actual values. mod1.trend %&gt;% augment() %&gt;% ggplot(aes(y = price, x = Year, colour = &quot;blue&quot;)) + geom_line() + geom_point() + geom_line(aes(y = .fitted, colour = &quot;Trend&quot;), size = 1.2, lty = &quot;dashed&quot;) + labs(title = &quot;Trend Model Fit&quot;, subtitle = &quot;In-Sample&quot;) + theme_bw() 7.2.2 Method 2: Naive Model (with drift) Let us assume that we have no idea of where the prices might go next. Under that condition, we could explore a naive forecasting approach. Additionally, since we noticed a pronounced trend in the series, we will account for that by including a drift term. We will use the code chunks below to accomplish this. mod2.drift &lt;- train %&gt;% model(drift = RW(price ~ drift())) Here is a plot of the in sample fit. mod2.drift %&gt;% augment() %&gt;% ggplot(aes(y = price, x = Year, colour = &quot;blue&quot;)) + geom_line() + geom_point() + geom_line(aes(y = .fitted, colour = &quot;Trend&quot;), size = 1.2) + labs(title = &quot;RW + Drift Model Fit&quot;, subtitle = &quot;In-Sample&quot;) + theme_bw() ## Warning: Removed 1 row containing missing values (`geom_line()`). 7.2.3 Method 3: Using Stocks-to-Use Approach In the last module, we explored the concept of accounting for structural breaks in the data. In particular, we split the data into different regimes and forecasted prices accordingly. We will utilize the same approach and use OLS regressions to help in the forecasting process. Our first step requires that we create market conditions dummy variables. The process is detailed in Module 6. weak &lt;- c(2009, 2014:2015) mod2 &lt;- c(2007:2008, 2013) mod1 &lt;- 2010 strong &lt;- 2011:2012 #Drop 2006, and all years after 2015. subdata &lt;- su.data %&gt;% filter(Year %in% c(1990:2005, 2007:2015)) %&gt;% mutate(weak = ifelse(Year %in% weak, 1,0), mod2 = ifelse(Year %in% mod2, 1,0), mod1 = ifelse(Year %in% mod1, 1,0), strong = ifelse(Year %in% strong, 1,0)) subdata %&gt;% head() ## # A tsibble: 6 x 8 [1Y] ## Year su price ratio weak mod2 mod1 strong ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1990 0.196 2.28 0.0511 0 0 0 0 ## 2 1991 0.139 2.37 0.0720 0 0 0 0 ## 3 1992 0.249 2.07 0.0402 0 0 0 0 ## 4 1993 0.112 2.5 0.0896 0 0 0 0 ## 5 1994 0.166 2.26 0.0603 0 0 0 0 ## 6 1995 0.0500 3.24 0.200 0 0 0 0 Now to perform the relevant regressions: mod3.stock &lt;- subdata %&gt;% model( TSLM(price ~ ratio + weak + mod2 + mod1 + strong) ) mod3.stock %&gt;% report() ## Series: price ## Model: TSLM ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.2994 -0.1125 0.0000 0.1118 0.2994 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.62417 0.09947 16.33 1.23e-12 *** ## ratio 8.52790 1.18120 7.22 7.43e-07 *** ## weak 1.32899 0.11305 11.76 3.66e-10 *** ## mod2 1.89273 0.11366 16.65 8.64e-13 *** ## mod1 2.56885 0.19122 13.43 3.77e-11 *** ## strong 3.81502 0.14990 25.45 3.83e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.1796 on 19 degrees of freedom ## Multiple R-squared: 0.9868, Adjusted R-squared: 0.9833 ## F-statistic: 283.9 on 5 and 19 DF, p-value: &lt; 2.22e-16 Likewise, we can produce a plot of the actual and fitted values from the mod3.stock regression above mod3.stock %&gt;% augment() %&gt;% ggplot(aes(x = Year, y = price, colour = &quot;Actual&quot;)) + geom_line() + geom_point() + geom_line(aes(y = .fitted, colour = &quot;Stocks/Use&quot;), size = 1.2) + labs(title = &quot;Stocks-to-Use Model Fit&quot;, subtitle = &quot;In-Sample&quot;) + theme_bw() 7.3 Out-of-sample forecasts Looking at the in-sample fits of each of the three graphs above, one could conclude that the Stocks-to-Use model fits the training data best. We will set aside that debate for now and focus instead on the out-of-sample predictions on each model. Recall that our out of sample predictions will be for the 5 years (2016–2020) we held out earlier. 7.3.1 Method 1: Trend We can use the forecast option with the appropriate horizon (h = 5). f.mod1 &lt;- mod1.trend %&gt;% forecast(h = 5) f.mod1 ## # A fable: 5 x 4 [1Y] ## # Key: .model [1] ## .model Year price .mean ## &lt;chr&gt; &lt;dbl&gt; &lt;dist&gt; &lt;dbl&gt; ## 1 trend 2016 N(4.8, 1.2) 4.75 ## 2 trend 2017 N(4.9, 1.2) 4.87 ## 3 trend 2018 N(5, 1.3) 4.99 ## 4 trend 2019 N(5.1, 1.3) 5.11 ## 5 trend 2020 N(5.2, 1.3) 5.23 In turn, the plot would be as follows: f.mod1 %&gt;% autoplot(train, level = NULL) + autolayer(test,price, color = &quot;red&quot;) + labs(title = &quot;Linear Trend Model Forecast&quot;) + theme_bw() The red line (actual values held out) are always lower than the forecasts of this model. Here, the trend model has a tendency to over predict the true values. 7.3.2 Method 2: Random Walk + Drfit Model We can generate and display the forecasted values (from the RW function) for the 5 periods of interest. f.mod2 &lt;- mod2.drift %&gt;% forecast(h = 5) f.mod2 ## # A fable: 5 x 4 [1Y] ## # Key: .model [1] ## .model Year price .mean ## &lt;chr&gt; &lt;dbl&gt; &lt;dist&gt; &lt;dbl&gt; ## 1 drift 2016 N(3.7, 0.67) 3.66 ## 2 drift 2017 N(3.7, 1.4) 3.72 ## 3 drift 2018 N(3.8, 2.2) 3.77 ## 4 drift 2019 N(3.8, 3) 3.82 ## 5 drift 2020 N(3.9, 3.9) 3.88 Plotting the results we have: f.mod2 %&gt;% autoplot(train, level = NULL) + autolayer(test,price, color = &quot;red&quot;) + labs(title = &quot;Random Walk with Drift Forecast&quot;) + theme_bw() In the earlier years, the random walk model with drift tends to over predict. Towards the latter years however, the trend is not step enough and therefore lags the true value (is under predicted). 7.3.3 Method 3: Stocks-to-Use Approach The forecast for this approach is slightly more involved but not complicated. As we did in Module 6, we will assign all years in the test set (the 5 years out-of-sample) to a single regime (i.e. all to weak, or moderate2, etc.). Also, to help with your forecasting, we will assume that we have the gift of perfect foresight relating to the stocks-to-use ratio (ratio). Our task therefore, is simply to use this method to forecast prices. scenarios5 &lt;- scenarios( weak = new_data(train,5) %&gt;% mutate(ratio = test[[&quot;ratio&quot;]], weak = rep(1,5), mod2 = rep(0,5), mod1 = rep(0,5), strong = rep(0,5)), moderate2 = new_data(train,5) %&gt;% mutate(ratio = test[[&quot;ratio&quot;]], weak = rep(0,5), mod2 = rep(1,5), mod1 = rep(0,5), strong = rep(0,5)), moderate1 = new_data(train,5) %&gt;% mutate(ratio = test[[&quot;ratio&quot;]], weak = rep(0,5), mod2 = rep(0,5), mod1 = rep(1,5), strong = rep(0,5)), strong = new_data(train,5) %&gt;% mutate(ratio = test[[&quot;ratio&quot;]], weak = rep(0,5), mod2 = rep(0,5), mod1 = rep(0,5), strong = rep(1,5)), names_to = &quot;Scenario&quot; ) forecast5 &lt;- mod3.stock %&gt;% forecast(new_data = scenarios5) train %&gt;% autoplot(price, size = 1.5) + autolayer(forecast5, size = 1.2, level = NULL) + autolayer(test, price, color = &quot;red&quot;, size = 1.2) + labs(title = &quot;Scenario Price Forecasts for Next 5 years&quot;) + theme_bw() The plot reveals that the weak regime more closely mirrors the prices observed in the last 5 years of the sample. Caution should be taken with interpreting these results as we used the observed (true) values for the reciprocal of the stocks-to-use ratio, \\(\\frac{1}{x}\\), for those years in our forecasts.3 In actuality, we would have to forecast those as well, or use expert judgement to come up with future values. 7.4 Model Evaluation Now that we have the three competing models, we need a more formal way of determining the “best” model. There are several such statistical tests but we will focus on 3 in particular. Before we do, it is worth defining the prediction error. The prediction error is: \\[e_t = (p_t - f_t)\\] Where \\(p_t\\) is the actual price and \\(f_t\\) is the forecast we made from each of the three methods above. We will next compute the Root Mean Squared Error (RMSE), Mean percentage error (MPE), and Mean Absolute Percentage Error (MAPE) as follows: \\[ RMSE = \\sqrt{\\frac{1}{5} \\sum_{t = 2016}^{2020}(e_t^2)}\\] \\[ MPE = \\frac{1}{5} \\sum_{t = 2016}^{2020}\\bigg(\\frac{e_t}{p_t}\\bigg)\\times 100 \\] \\[ MAPE = \\frac{1}{5} \\sum_{t = 2016}^{2020}\\bigg|\\frac{e_t}{p_t}\\bigg|\\times 100\\] For simplicity, we will create a user defined function to achieve our calculations. selection &lt;- function(actual, forecast){ TT &lt;- length(actual) err &lt;- actual - forecast rmse &lt;- sqrt((1/TT) * sum(err^2)) mpe &lt;- (1/TT)* sum(err/actual)*100 mape &lt;- 1/TT*sum(abs(err/actual))*100 return(list(&quot;RMSE&quot; = rmse, &quot;MPE&quot; = mpe, &quot;MAPE&quot; = mape)) } We can now use our function to compute the 3 statistics for each model. r1 &lt;- selection(actual = test[[&quot;price&quot;]], forecast = f.mod1[[&quot;.mean&quot;]]) r2 &lt;- selection(actual = test[[&quot;price&quot;]], forecast = f.mod2[[&quot;.mean&quot;]]) r3 &lt;- selection(actual = test[[&quot;price&quot;]], forecast = (forecast5 %&gt;% filter(Scenario== &quot;weak&quot;))[[&quot;.mean&quot;]]) r4 &lt;- selection(actual = test[[&quot;price&quot;]], forecast = (forecast5 %&gt;% filter(Scenario== &quot;moderate2&quot;))[[&quot;.mean&quot;]]) r5 &lt;- selection(actual = test[[&quot;price&quot;]], forecast = (forecast5 %&gt;% filter(Scenario== &quot;moderate1&quot;))[[&quot;.mean&quot;]]) r6 &lt;- selection(actual = test[[&quot;price&quot;]], forecast = (forecast5 %&gt;% filter(Scenario== &quot;strong&quot;))[[&quot;.mean&quot;]] ) rbind(&quot;Trend&quot; = r1, &quot;RW + Drift&quot; = r2, &quot;Stocks/Use Weak&quot; = r3, &quot;Stocks/Use Moderate2&quot; = r4, &quot;Stocks/Use Moderate1&quot; = r5, &quot;Stocks/Use Strong&quot; = r6) ## RMSE MPE MAPE ## Trend 1.359062 -37.44522 37.44522 ## RW + Drift 0.342947 -3.904987 8.668624 ## Stocks/Use Weak 0.1760026 -0.01884601 3.953331 ## Stocks/Use Moderate2 0.5761378 -15.58265 15.58265 ## Stocks/Use Moderate1 1.237411 -34.24926 34.24926 ## Stocks/Use Strong 2.477306 -68.65396 68.65396 The decision rule requires that, under each test (the column), we choose the model with the statistic value closest to zero. RMSE and MAPE get rid of the sign of error by squaring or taking the absolute value, thus they indicate the average size of forecast error, regardless of direction. MPE however, conserves the sign of error and indicates whether positive and negative errors cancel out (MPE=0, no bias) or dominate (MPE&gt; or &lt;0, under or over-prediction). From our calculations above, the Stocks/Use model under a weak-price regime is preferred by all three model selection criteria. Further analysis of forecast errors may include Theil’s U statistic to compare RMSE and MAPE to a naive forecast alternative and a test of bias to assess whether MPE is significantly different from zero. These various accuracy tests are discussed in Module 2. This publication from ABARES provides additional examples (and measures) of accuracy evaluation for Australian forecasts. For a refresher, please see the ratio variable computed in Section 6.1.2.↩︎ "]]
